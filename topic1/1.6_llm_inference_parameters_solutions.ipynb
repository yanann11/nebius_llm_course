{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanann11/nebius_llm_course/blob/main/topic1/1.6_llm_inference_parameters_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLMOps Essentials, practice 1.6. LLM Inference Parameters\n",
        "\n",
        "# Practice Solutions"
      ],
      "metadata": {
        "id": "Vm506vpf9u9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting ready"
      ],
      "metadata": {
        "id": "mcm2WOgK8JpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "WqCgRtIRIcN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "with open(\"nebius_api_key\", \"r\") as file:\n",
        "    nebius_api_key = file.read().strip()\n",
        "\n",
        "os.environ[\"NEBIUS_API_KEY\"] = nebius_api_key"
      ],
      "metadata": {
        "id": "NRpRGdl5IdJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be calling APIs quite often in this notebook, so let's define a shortcut fuction to avoid repeating all the code:"
      ],
      "metadata": {
        "id": "8ElsBJ68uacB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "def prettify_string(text, max_line_length=80):\n",
        "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
        "\n",
        "    Args:\n",
        "        text: The string to print.\n",
        "        max_line_length: The maximum length of each line.\n",
        "    \"\"\"\n",
        "\n",
        "    output_lines = []\n",
        "    lines = text.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        current_line = \"\"\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
        "                current_line += word + \" \"\n",
        "            else:\n",
        "                output_lines.append(current_line.strip())\n",
        "                current_line = word + \" \"\n",
        "        output_lines.append(current_line.strip())  # Append the last line\n",
        "    return \"\\n\".join(output_lines)\n",
        "\n",
        "def answer_with_llm(prompt: str,\n",
        "                    system_prompt=\"You are a helpful assistant\",\n",
        "                    max_tokens=512,\n",
        "                    client=nebius_client,\n",
        "                    model=llama_8b_model,\n",
        "                    prettify=True,\n",
        "                    temperature=0.6,\n",
        "                    top_p=None,\n",
        "                    frequency_penalty=0) -> str:\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    if system_prompt:\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            }\n",
        "        )\n",
        "\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        frequency_penalty=frequency_penalty\n",
        "    )\n",
        "\n",
        "    if prettify:\n",
        "        return prettify_string(completion.choices[0].message.content)\n",
        "    else:\n",
        "        return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "YTlC-5omIVOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "def answer_with_logprobs(prompt: str,\n",
        "                    system_prompt=\"You are a helpful assistant\",\n",
        "                    max_tokens=512,\n",
        "                    temperature=0.6,\n",
        "                    logprobs=True,\n",
        "                    top_logprobs=5,\n",
        "                    client=nebius_client,\n",
        "                    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
        "    completion = nebius_client.chat.completions.create(\n",
        "      model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "      messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        logprobs=True,\n",
        "        top_logprobs=5,\n",
        "    )\n",
        "\n",
        "    return completion\n",
        "\n",
        "completion = answer_with_logprobs(\"\"\"What is at the heart of every story?\n",
        "                Answer in exactly six words\"\"\")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tue3sUHKflB0",
        "outputId": "9b949dc4-0ce8-4754-efc9-650173fef25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A character's transformation or emotional growth.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def logprobs_to_table(logprobs_content):\n",
        "    '''\n",
        "    Creates a pandas data frame showcasing:\n",
        "    - The actually generated token with its log probability\n",
        "    - The top tokens and their log probabilities\n",
        "    '''\n",
        "    generated_tokes = []\n",
        "    generated_logprobs = []\n",
        "    # At 0-th position in the logprobs_content[0].top_logprobs\n",
        "    # there's always the actually generated token\n",
        "    # We don't include it\n",
        "    top_tokens = [[] for _ in range(len(logprobs_content[0].top_logprobs) - 1)]\n",
        "    top_logprobs = [[] for _ in range(len(logprobs_content[0].top_logprobs) - 1)]\n",
        "    for entry in logprobs_content:\n",
        "        generated_tokes.append(entry.token)\n",
        "        generated_logprobs.append(entry.logprob)\n",
        "\n",
        "        for j, top_logprob in enumerate(entry.top_logprobs[1:]):\n",
        "            top_tokens[j].append(top_logprob.token)\n",
        "            top_logprobs[j].append(top_logprob.logprob)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"gen_token\": generated_tokes,\n",
        "        \"gen_logp\": generated_logprobs\n",
        "    })\n",
        "    for j in range(len(top_tokens)):\n",
        "        df[f\"{j}_token\"] = top_tokens[j]\n",
        "        df[f\"{j}_logp\"] = top_logprobs[j]\n",
        "    return df"
      ],
      "metadata": {
        "id": "whuFP33CiMIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice: exploring LLM parameters and creativity"
      ],
      "metadata": {
        "id": "C5xHu-RjnA36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1. Favourite names and occupations\n",
        "\n",
        "In this task, you'll try to understand if LLMs have favourite fantasy names, occupations, and jobs. For that, we suggest you to:\n",
        "\n",
        "* Choose several LLMs (for example, three Llamas-3.1 and Qwen2.5-32B-Instruct)\n",
        "* For each, run `answer_with_llm` with `temperature=0.6` for `n_trials=20` times and prompts\n",
        "\n",
        "  * `Suggest a name for a fantasy character. Only output the name.`\n",
        "  * `Suggest an occupation for a fantasy character. Only output the name of the occupation.`\n",
        "  * `Suggest a hobby for a fantasy character. Only output the name of the hobby.`\n",
        "\n",
        "  Are there many different options? Is there a hope for an LLM-generated fantasy character to be a smith or a carpenter?..\n",
        "\n",
        "* Repeat the experiment with `temperature=1`.\n",
        "\n",
        "* Now, for each model and for each prompt, run `answer_with_logprobs` with `temperature=0.6`. Look at the predicted log probabilities. Do some of them dominate the distribution? (That is, are some of them significantly larger than the others?)\n",
        "\n",
        "* Think about a way of generating more diverse names and occupations."
      ],
      "metadata": {
        "id": "3q0gYHnonS3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR EXPERIMENTS HERE>"
      ],
      "metadata": {
        "id": "uSIbL4ajuOdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution** Let's start with some experiments."
      ],
      "metadata": {
        "id": "loqLG0k8uRUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "n_trials = 20\n",
        "prompts = [\n",
        "    \"\"\"Suggest a name for a fantasy character. Only output the name.\"\"\",\n",
        "    \"\"\"Suggest an occupation for a fantasy character. Only output the occupation name.\"\"\",\n",
        "    \"\"\"Suggest an hobby for a fantasy character. Only output the hobby name.\"\"\"\n",
        "]\n",
        "models = [\n",
        "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "    \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
        "    \"Qwen/Qwen2.5-32B-Instruct\"\n",
        "]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model in models:\n",
        "    for prompt in prompts:\n",
        "        results[(model, prompt)] = []\n",
        "        print(f\"Processing:\\n\\tmodel: {model}\\n\\tprompt: {prompt}\")\n",
        "        for _ in tqdm(range(n_trials)):\n",
        "            answer = answer_with_llm(prompt, model=model, temperature=0.6)\n",
        "            results[(model, prompt)].append(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNjvv-SoURVy",
        "outputId": "d02cc441-85f6-4440-de25-621a04f6a705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:10<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:11<00:00,  1.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:47<00:00,  2.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:01<00:00,  3.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:56<00:00,  2.83s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"model = {key[0]}\\nprompt = {key[1]}:\\n\")\n",
        "    for k, v in Counter(value).items():\n",
        "        print(f\"\\t{k}: {v}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV2ume_PqUmH",
        "outputId": "161d2da7-fe4b-4e88-f914-c5bc026d2f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tEira Shadowglow: 9\n",
            "\tAethoniel Darkshadow: 1\n",
            "\tKaelin Darkhaven: 3\n",
            "\tKaelith Sunshadow: 4\n",
            "\tEryndor Thorneblack: 1\n",
            "\tKaelara Moonwhisper: 2\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tDreamweaver: 1\n",
            "\tLuminari Weaver: 1\n",
            "\tMoonweaver: 1\n",
            "\tMoonwhisper Cartographer: 10\n",
            "\tMaster Cartographer: 2\n",
            "\tLuminari Cartographer: 1\n",
            "\tClockwork Engineer: 2\n",
            "\tChronokeeper: 1\n",
            "\tAeromancer: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tLuminous Terracotta Crafting: 1\n",
            "\tMoonwhisper Illumination: 1\n",
            "\tMoonlit Botany: 3\n",
            "\tLuminous Cartography: 1\n",
            "\tLuminari Glassblowing: 1\n",
            "\tCrystalography: 1\n",
            "\tLuminari Gardening: 1\n",
            "\tDreamweaving: 2\n",
            "\tMythweaving: 2\n",
            "\tClockwork Insect Collecting: 1\n",
            "\tMoonlight Cartomancy: 1\n",
            "\tLuminous Gardening: 2\n",
            "\tLuminous Glassblowing: 1\n",
            "\tMoonlit Illumination: 1\n",
            "\tMoonlight Illumination: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tLyriquin Darkshadow: 1\n",
            "\tElyriana Moonwhisper: 3\n",
            "\tEira Shadowglow: 4\n",
            "\tElyriana Starweaver: 1\n",
            "\tAethoniel: 1\n",
            "\tLyriath Blackwood: 3\n",
            "\tElyriana Darkfire: 1\n",
            "\tEiravyn: 1\n",
            "\tEryndor Thorne: 3\n",
            "\tElyriana: 1\n",
            "\tLyrieth Starweaver: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tMythweaver: 8\n",
            "\tMythologist: 1\n",
            "\tShadow Weaver: 2\n",
            "\tMythographer: 1\n",
            "\tMythkeeper: 4\n",
            "\tArcane Cartographer: 1\n",
            "\tDreamweaver: 1\n",
            "\tChronicler of Ancient Lore: 1\n",
            "\tSkyship Engineer: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tStargazing Cartography: 7\n",
            "\tMoonlit Gardening: 2\n",
            "\t\"Starseed Gardening\": 1\n",
            "\t\"Stardust Cartography\": 1\n",
            "\tMoonwhispering: 2\n",
            "\tStarglass Crafting: 2\n",
            "\tMoonlit Cartography: 1\n",
            "\tStardust Cartography: 2\n",
            "\tMythril Smithing: 1\n",
            "\tStarseeking: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tEiraethil: 1\n",
            "\tEiraethon: 9\n",
            "\tEira Shadowglow: 1\n",
            "\tKaelorin: 2\n",
            "\tEiraethris: 1\n",
            "\tEiraethor: 1\n",
            "\tElyriana: 1\n",
            "\tKaelorath: 1\n",
            "\tXylaraeth: 1\n",
            "\tEiraethor Thorne: 1\n",
            "\tKaelinora: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tShadow Weaver: 19\n",
            "\tMoonwhisper Archer: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tShadow Weaving: 4\n",
            "\tShadow weaving.: 1\n",
            "\tShadowcrafting: 2\n",
            "\tDragonwatching.: 1\n",
            "\tMoonlit Cartography: 4\n",
            "\tDragonbone carving.: 1\n",
            "\tStargazing Cartography: 1\n",
            "\tDragonbone carving: 1\n",
            "\tDragonwatching: 1\n",
            "\tMoonstone carving.: 1\n",
            "\tStellar Cartography: 2\n",
            "\tShadow Weaving.: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tEldrin Stormweaver: 15\n",
            "\tEliandra Stormweaver: 1\n",
            "\tEldrin Moonwhisper: 1\n",
            "\tEldric Stormweaver: 1\n",
            "\tThalorien Stormweaver: 1\n",
            "\tElowen Nightwhisper: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tDragon Tamer: 15\n",
            "\tWizard: 2\n",
            "\tDragonslayer: 1\n",
            "\tArcane Librarian: 1\n",
            "\tEnchanter: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tDragon Riding: 4\n",
            "\tMagic Card Crafting: 2\n",
            "\tDragonriding: 1\n",
            "\tDragon Painting: 4\n",
            "\tDragon Sketching: 1\n",
            "\tDragon Whispering: 1\n",
            "\tSpellcrafting: 1\n",
            "\tWorld Exploration: 1\n",
            "\tDragon Training: 4\n",
            "\tSwordsmithing: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, names and occupations are very repetitive. For example, Llama-3.1-8B seems to adore the name Eira Shadowglow; Llama-3.1-405B loves Shawowweaving (whatever that could be...); and Qwen is fond of dragon taming.\n",
        "\n",
        "At first glance, hobbies seem a little more diverse, but if you look closely, you'll see the same shadows and dragons, just with some additional details.\n",
        "\n",
        "So, let's look at the log probabilities. We won't output them for all the models, only for Llama-3.1-8B:"
      ],
      "metadata": {
        "id": "7k-rleLjuYSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = answer_with_logprobs(\n",
        "    \"\"\"Create a name for a fantasy character. Only output the name.\"\"\",\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    temperature=0.6)\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LKqVOjHXrzlG",
        "outputId": "7650f0e2-d4ea-4786-9572-7077bbb578a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eira Shadowglow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_to_table(completion.choices[0].logprobs.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "b31zN8ewUji6",
        "outputId": "2f5ae978-65d9-4c59-9964-926594594fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token  gen_logp 0_token     0_logp 1_token     1_logp     2_token  \\\n",
              "0         E -0.877382       K  -0.669081      Ly  -3.220751           A   \n",
              "1       ira -0.334373      ir  -1.740394      ly  -2.912078          ry   \n",
              "2    Shadow -0.021107     eth  -3.952759       F  -7.454794           L   \n",
              "3        gl -0.000049    leaf -10.883694       g -11.144070         gle   \n",
              "4        ow  0.000000     ade -19.528072     are -21.845404         ows   \n",
              "5           -0.000019       . -10.870647      en -15.661533  <|eom_id|>   \n",
              "\n",
              "      2_logp 3_token     3_logp  \n",
              "0  -3.923761      Th  -4.496584  \n",
              "1  -3.016231      ri  -5.567897  \n",
              "2  -8.053654   Flynn  -8.092710  \n",
              "3 -12.107454    fire -12.419903  \n",
              "4 -22.574451      OW -22.873882  \n",
              "5 -16.039078       e -17.249817  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b37266f-19d1-47d7-b033-98d03c572ab3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E</td>\n",
              "      <td>-0.877382</td>\n",
              "      <td>K</td>\n",
              "      <td>-0.669081</td>\n",
              "      <td>Ly</td>\n",
              "      <td>-3.220751</td>\n",
              "      <td>A</td>\n",
              "      <td>-3.923761</td>\n",
              "      <td>Th</td>\n",
              "      <td>-4.496584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ira</td>\n",
              "      <td>-0.334373</td>\n",
              "      <td>ir</td>\n",
              "      <td>-1.740394</td>\n",
              "      <td>ly</td>\n",
              "      <td>-2.912078</td>\n",
              "      <td>ry</td>\n",
              "      <td>-3.016231</td>\n",
              "      <td>ri</td>\n",
              "      <td>-5.567897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Shadow</td>\n",
              "      <td>-0.021107</td>\n",
              "      <td>eth</td>\n",
              "      <td>-3.952759</td>\n",
              "      <td>F</td>\n",
              "      <td>-7.454794</td>\n",
              "      <td>L</td>\n",
              "      <td>-8.053654</td>\n",
              "      <td>Flynn</td>\n",
              "      <td>-8.092710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gl</td>\n",
              "      <td>-0.000049</td>\n",
              "      <td>leaf</td>\n",
              "      <td>-10.883694</td>\n",
              "      <td>g</td>\n",
              "      <td>-11.144070</td>\n",
              "      <td>gle</td>\n",
              "      <td>-12.107454</td>\n",
              "      <td>fire</td>\n",
              "      <td>-12.419903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ow</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ade</td>\n",
              "      <td>-19.528072</td>\n",
              "      <td>are</td>\n",
              "      <td>-21.845404</td>\n",
              "      <td>ows</td>\n",
              "      <td>-22.574451</td>\n",
              "      <td>OW</td>\n",
              "      <td>-22.873882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>-0.000019</td>\n",
              "      <td>.</td>\n",
              "      <td>-10.870647</td>\n",
              "      <td>en</td>\n",
              "      <td>-15.661533</td>\n",
              "      <td>&lt;|eom_id|&gt;</td>\n",
              "      <td>-16.039078</td>\n",
              "      <td>e</td>\n",
              "      <td>-17.249817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b37266f-19d1-47d7-b033-98d03c572ab3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b37266f-19d1-47d7-b033-98d03c572ab3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b37266f-19d1-47d7-b033-98d03c572ab3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-200f016e-6d40-4c74-9578-810dd062270a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-200f016e-6d40-4c74-9578-810dd062270a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-200f016e-6d40-4c74-9578-810dd062270a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_to_table(completion\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"E\",\n          \"ira\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35459759608558683,\n        \"min\": -0.8773823380470276,\n        \"max\": 0.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.8773823380470276,\n          -0.33437252044677734,\n          -1.9311717551317997e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"K\",\n          \"ir\",\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.193565431657846,\n        \"min\": -19.528072357177734,\n        \"max\": -0.6690807938575745,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.6690807938575745,\n          -1.7403936386108398,\n          -10.870647430419922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Ly\",\n          \"ly\",\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.423141253237178,\n        \"min\": -21.84540367126465,\n        \"max\": -2.9120779037475586,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -3.2207508087158203,\n          -2.9120779037475586,\n          -15.66153335571289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"A\",\n          \"ry\",\n          \"<|eom_id|>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.524198255256152,\n        \"min\": -22.574451446533203,\n        \"max\": -3.016230583190918,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -3.9237613677978516,\n          -3.016230583190918,\n          -16.039077758789062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Th\",\n          \"ri\",\n          \"e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.192176357578303,\n        \"min\": -22.873882293701172,\n        \"max\": -4.496583938598633,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -4.496583938598633,\n          -5.567896842956543,\n          -17.24981689453125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = answer_with_logprobs(\n",
        "    \"\"\"Create an occupation for a fantasy character. Only output the occupation name.\"\"\",\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    temperature=0.6)\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g2SwSO6BVBJe",
        "outputId": "9fd64e16-ba25-4e59-f2a2-1379a2fe2b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dreamweaver'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_to_table(completion.choices[0].logprobs.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "HsY2itROVDtN",
        "outputId": "5a8891af-0856-49bf-ac26-8a072af923f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token  gen_logp 0_token     0_logp 1_token     1_logp      2_token  \\\n",
              "0     Dream -1.501330    Moon  -0.746245       L  -1.553404          Sky   \n",
              "1        we -0.040886  walker  -3.217453       w -12.695078        catch   \n",
              "2      aver  0.000000   ilder -19.397884     ver -19.892593         eper   \n",
              "3           -0.136773      of  -2.167693       .  -4.498044   Apprentice   \n",
              "\n",
              "      2_logp 3_token     3_logp  \n",
              "0  -3.896773  Shadow  -4.000923  \n",
              "1 -14.231287    seek -15.259766  \n",
              "2 -20.361267   avery -20.829943  \n",
              "3  -6.789336     for  -8.078189  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bc5fee2-9397-475c-9b58-32e472850395\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dream</td>\n",
              "      <td>-1.501330</td>\n",
              "      <td>Moon</td>\n",
              "      <td>-0.746245</td>\n",
              "      <td>L</td>\n",
              "      <td>-1.553404</td>\n",
              "      <td>Sky</td>\n",
              "      <td>-3.896773</td>\n",
              "      <td>Shadow</td>\n",
              "      <td>-4.000923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>we</td>\n",
              "      <td>-0.040886</td>\n",
              "      <td>walker</td>\n",
              "      <td>-3.217453</td>\n",
              "      <td>w</td>\n",
              "      <td>-12.695078</td>\n",
              "      <td>catch</td>\n",
              "      <td>-14.231287</td>\n",
              "      <td>seek</td>\n",
              "      <td>-15.259766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aver</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ilder</td>\n",
              "      <td>-19.397884</td>\n",
              "      <td>ver</td>\n",
              "      <td>-19.892593</td>\n",
              "      <td>eper</td>\n",
              "      <td>-20.361267</td>\n",
              "      <td>avery</td>\n",
              "      <td>-20.829943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>-0.136773</td>\n",
              "      <td>of</td>\n",
              "      <td>-2.167693</td>\n",
              "      <td>.</td>\n",
              "      <td>-4.498044</td>\n",
              "      <td>Apprentice</td>\n",
              "      <td>-6.789336</td>\n",
              "      <td>for</td>\n",
              "      <td>-8.078189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bc5fee2-9397-475c-9b58-32e472850395')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1bc5fee2-9397-475c-9b58-32e472850395 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1bc5fee2-9397-475c-9b58-32e472850395');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca1276f6-162a-4a4a-96ad-9c9fc52d50c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca1276f6-162a-4a4a-96ad-9c9fc52d50c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca1276f6-162a-4a4a-96ad-9c9fc52d50c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_to_table(completion\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"we\",\n          \"\",\n          \"Dream\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7233298603663814,\n        \"min\": -1.5013296604156494,\n        \"max\": 0.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.04088638350367546,\n          -0.1367729753255844,\n          -1.5013296604156494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"walker\",\n          \" of\",\n          \"Moon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.735935808207165,\n        \"min\": -19.397884368896484,\n        \"max\": -0.7462446093559265,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -3.2174534797668457,\n          -2.1676928997039795,\n          -0.7462446093559265\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"w\",\n          \".\",\n          \"L\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.292172047661417,\n        \"min\": -19.892593383789062,\n        \"max\": -1.5534040927886963,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -12.695077896118164,\n          -4.498044013977051,\n          -1.5534040927886963\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"catch\",\n          \" Apprentice\",\n          \"Sky\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.4353058953337445,\n        \"min\": -20.36126708984375,\n        \"max\": -3.896772623062134,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -14.231287002563477,\n          -6.789336204528809,\n          -3.896772623062134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"seek\",\n          \" for\",\n          \"Shadow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.482260524528258,\n        \"min\": -20.82994270324707,\n        \"max\": -4.000923156738281,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -15.259765625,\n          -8.0781888961792,\n          -4.000923156738281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = answer_with_logprobs(\n",
        "    \"\"\"Suggest a hobby for a fantasy character. Only output the hobby name.\"\"\",\n",
        "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "    temperature=0.6)\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W--dt0opVGId",
        "outputId": "b001c049-1ee8-4712-95e2-f3b7ef5e5c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Luminous Flower Arranging'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_to_table(completion.choices[0].logprobs.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ULP2epK7VLNe",
        "outputId": "320bdcef-50fc-40bf-fa6b-46b8c853b98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token  gen_logp   0_token    0_logp       1_token     1_logp 2_token  \\\n",
              "0         L -0.784618      Moon -1.565740            My  -1.721966       A   \n",
              "1      umin -0.007116        um -4.980264          unar  -9.276439    apid   \n",
              "2       ous -0.416527       ari -1.093499         arium  -5.259488      we   \n",
              "3    Flower -7.991506      Cart -1.143662         Glass  -1.169700    Gard   \n",
              "4       Arr -0.197764     Press -1.760010   arrangement  -5.457326    Gard   \n",
              "5    anging -0.263823  angement -1.461547           ang -11.355769   anger   \n",
              "6           -0.004796         . -5.342469           for -16.421394       !   \n",
              "\n",
              "      2_logp     3_token     3_logp  \n",
              "0  -3.232136          St  -3.909109  \n",
              "1  -9.640964          ac -10.890759  \n",
              "2  -8.383981       arian  -9.529628  \n",
              "3  -1.664411         Bot  -2.862132  \n",
              "4  -6.902404          We  -7.097684  \n",
              "5 -13.230464     angling -22.109228  \n",
              "6 -16.473469  <|eom_id|> -16.994217  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a194a534-0b05-46a3-bccf-950b76055b89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L</td>\n",
              "      <td>-0.784618</td>\n",
              "      <td>Moon</td>\n",
              "      <td>-1.565740</td>\n",
              "      <td>My</td>\n",
              "      <td>-1.721966</td>\n",
              "      <td>A</td>\n",
              "      <td>-3.232136</td>\n",
              "      <td>St</td>\n",
              "      <td>-3.909109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>umin</td>\n",
              "      <td>-0.007116</td>\n",
              "      <td>um</td>\n",
              "      <td>-4.980264</td>\n",
              "      <td>unar</td>\n",
              "      <td>-9.276439</td>\n",
              "      <td>apid</td>\n",
              "      <td>-9.640964</td>\n",
              "      <td>ac</td>\n",
              "      <td>-10.890759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ous</td>\n",
              "      <td>-0.416527</td>\n",
              "      <td>ari</td>\n",
              "      <td>-1.093499</td>\n",
              "      <td>arium</td>\n",
              "      <td>-5.259488</td>\n",
              "      <td>we</td>\n",
              "      <td>-8.383981</td>\n",
              "      <td>arian</td>\n",
              "      <td>-9.529628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Flower</td>\n",
              "      <td>-7.991506</td>\n",
              "      <td>Cart</td>\n",
              "      <td>-1.143662</td>\n",
              "      <td>Glass</td>\n",
              "      <td>-1.169700</td>\n",
              "      <td>Gard</td>\n",
              "      <td>-1.664411</td>\n",
              "      <td>Bot</td>\n",
              "      <td>-2.862132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Arr</td>\n",
              "      <td>-0.197764</td>\n",
              "      <td>Press</td>\n",
              "      <td>-1.760010</td>\n",
              "      <td>arrangement</td>\n",
              "      <td>-5.457326</td>\n",
              "      <td>Gard</td>\n",
              "      <td>-6.902404</td>\n",
              "      <td>We</td>\n",
              "      <td>-7.097684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>anging</td>\n",
              "      <td>-0.263823</td>\n",
              "      <td>angement</td>\n",
              "      <td>-1.461547</td>\n",
              "      <td>ang</td>\n",
              "      <td>-11.355769</td>\n",
              "      <td>anger</td>\n",
              "      <td>-13.230464</td>\n",
              "      <td>angling</td>\n",
              "      <td>-22.109228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td>-0.004796</td>\n",
              "      <td>.</td>\n",
              "      <td>-5.342469</td>\n",
              "      <td>for</td>\n",
              "      <td>-16.421394</td>\n",
              "      <td>!</td>\n",
              "      <td>-16.473469</td>\n",
              "      <td>&lt;|eom_id|&gt;</td>\n",
              "      <td>-16.994217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a194a534-0b05-46a3-bccf-950b76055b89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a194a534-0b05-46a3-bccf-950b76055b89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a194a534-0b05-46a3-bccf-950b76055b89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-699cf382-3cd7-4633-8ed2-3ddfb4394886\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-699cf382-3cd7-4633-8ed2-3ddfb4394886')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-699cf382-3cd7-4633-8ed2-3ddfb4394886 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_to_table(completion\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"L\",\n          \"umin\",\n          \"anging\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.9272936857028387,\n        \"min\": -7.9915056228637695,\n        \"max\": -0.004795716144144535,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.784618079662323,\n          -0.00711573613807559,\n          -0.26382339000701904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Moon\",\n          \"um\",\n          \"angement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8504373797527287,\n        \"min\": -5.342468738555908,\n        \"max\": -1.0934988260269165,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -1.5657403469085693,\n          -4.980264186859131,\n          -1.461546778678894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"My\",\n          \"unar\",\n          \"ang\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.473910866617955,\n        \"min\": -16.42139434814453,\n        \"max\": -1.1696996688842773,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -1.7219655513763428,\n          -9.27643871307373,\n          -11.355769157409668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"A\",\n          \"apid\",\n          \"!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.232855079001149,\n        \"min\": -16.473468780517578,\n        \"max\": -1.6644105911254883,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -3.232135534286499,\n          -9.640963554382324,\n          -13.230463981628418\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"St\",\n          \"ac\",\n          \"angling\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.968911087795704,\n        \"min\": -22.109228134155273,\n        \"max\": -2.8621320724487305,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -3.909108877182007,\n          -10.890759468078613,\n          -22.109228134155273\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that with `temperature=0.6`:\n",
        "\n",
        "- In names, `E` and `K` as starting tokens dominate everything else,\n",
        "- Also, `Shadow` is a very likely start of the second name.\n",
        "- In occupations, `Shadow`, `Moon`, and `L` are much more probable starting tokens than everything else.\n",
        "- The same is true for hobbies and starting tokens `L`, `Moon`, `My`.\n",
        "\n",
        "With `temperature=1`, it becomes a little bit better, although overall the diversity is still very low:"
      ],
      "metadata": {
        "id": "mKdBfV4wvUII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for model in models:\n",
        "    for prompt in prompts:\n",
        "        results[(model, prompt)] = []\n",
        "        print(f\"Processing:\\n\\tmodel: {model}\\n\\tprompt: {prompt}\")\n",
        "        for _ in tqdm(range(n_trials)):\n",
        "            answer = answer_with_llm(prompt, model=model, temperature=1)\n",
        "            results[(model, prompt)].append(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT03RHfWvsCd",
        "outputId": "e9b0ae6f-64f3-4732-d671-58cd81eb7385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:10<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:11<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:13<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:00<00:00,  3.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:56<00:00,  2.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:50<00:00,  2.55s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"model = {key[0]}\\nprompt = {key[1]}:\\n\")\n",
        "    print(Counter(value))\n",
        "    for k, v in Counter(value).items():\n",
        "        print(f\"\"\"\\t{k}: {v}\"\"\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-cWxaOOv0Vy",
        "outputId": "6921a92f-d3fe-44e6-fe37-92747edb1978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "Counter({'Eira Shadowglow': 4, 'Kaelith Sunshadow': 2, 'Kaelara Shadowglow': 1, 'Kaelin Darkhaven': 1, 'Kaelin Vaur\\n\\nWould you like a description or backstory for this character?': 1, 'Aethonaria Starweaver': 1, 'Eryndor Thorne': 1, 'Elyriath Moonwhisper': 1, 'Lythariel Darkhaven': 1, 'Kaelira Moonwhisper': 1, 'Elyndor Thorne': 1, 'Kaelara Darkhaven': 1, 'Kaelin Darkshadow': 1, 'Kaelara Moonwhisper': 1, 'Kaelin Darkshore': 1, 'EiraShadowglow': 1})\n",
            "\tEira Shadowglow: 4\n",
            "\tKaelara Shadowglow: 1\n",
            "\tKaelin Darkhaven: 1\n",
            "\tKaelin Vaur\n",
            "\n",
            "Would you like a description or backstory for this character?: 1\n",
            "\tAethonaria Starweaver: 1\n",
            "\tEryndor Thorne: 1\n",
            "\tElyriath Moonwhisper: 1\n",
            "\tLythariel Darkhaven: 1\n",
            "\tKaelith Sunshadow: 2\n",
            "\tKaelira Moonwhisper: 1\n",
            "\tElyndor Thorne: 1\n",
            "\tKaelara Darkhaven: 1\n",
            "\tKaelin Darkshadow: 1\n",
            "\tKaelara Moonwhisper: 1\n",
            "\tKaelin Darkshore: 1\n",
            "\tEiraShadowglow: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "Counter({'Apothecary': 1, 'Nightsworn Cartographer': 1, 'Glimmerweaver': 1, 'Duskrunner': 1, 'Moonwhisper Cartographer': 1, 'Wind Dancer': 1, 'Moonstone Geologist': 1, 'Wind Wanderer Navigator.': 1, 'Moonwhisper Dreamweaver': 1, 'Mistweaver Apothecary': 1, 'Dreamweaver': 1, 'Gravel Runner': 1, 'Wilderness Cartographer': 1, \"Necromancer's Apprentice\": 1, 'Aether Reader': 1, 'Shadow Weaver': 1, 'Moonwhisper Lunarweaver.': 1, 'Sand Sculptor of the Dunes': 1, 'Master Cartographer': 1, 'Aether Cartographer': 1})\n",
            "\tApothecary: 1\n",
            "\tNightsworn Cartographer: 1\n",
            "\tGlimmerweaver: 1\n",
            "\tDuskrunner: 1\n",
            "\tMoonwhisper Cartographer: 1\n",
            "\tWind Dancer: 1\n",
            "\tMoonstone Geologist: 1\n",
            "\tWind Wanderer Navigator.: 1\n",
            "\tMoonwhisper Dreamweaver: 1\n",
            "\tMistweaver Apothecary: 1\n",
            "\tDreamweaver: 1\n",
            "\tGravel Runner: 1\n",
            "\tWilderness Cartographer: 1\n",
            "\tNecromancer's Apprentice: 1\n",
            "\tAether Reader: 1\n",
            "\tShadow Weaver: 1\n",
            "\tMoonwhisper Lunarweaver.: 1\n",
            "\tSand Sculptor of the Dunes: 1\n",
            "\tMaster Cartographer: 1\n",
            "\tAether Cartographer: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "Counter({'Mythweaving.': 2, 'Clockwork Gardening': 2, 'Moonstone Etchings': 1, 'Star mapping': 1, 'Litereature Illumination.': 1, 'Crystalidge: Luminous Sculpting': 1, 'Shadow Puppetry': 1, 'Moonlit Botany': 1, 'Luminari Sculpting': 1, 'Mythweaving': 1, 'Aerial Cartography': 1, 'Luminari Mapping': 1, 'Luminari Etching': 1, 'Luminous Sculpting': 1, 'Crystal Growing': 1, 'Spellweaving': 1, 'Luminous Terraglass Collecting': 1, 'Dowsing for Ancient Runestones': 1})\n",
            "\tMoonstone Etchings: 1\n",
            "\tStar mapping: 1\n",
            "\tLitereature Illumination.: 1\n",
            "\tCrystalidge: Luminous Sculpting: 1\n",
            "\tMythweaving.: 2\n",
            "\tShadow Puppetry: 1\n",
            "\tMoonlit Botany: 1\n",
            "\tLuminari Sculpting: 1\n",
            "\tMythweaving: 1\n",
            "\tAerial Cartography: 1\n",
            "\tLuminari Mapping: 1\n",
            "\tLuminari Etching: 1\n",
            "\tLuminous Sculpting: 1\n",
            "\tCrystal Growing: 1\n",
            "\tClockwork Gardening: 2\n",
            "\tSpellweaving: 1\n",
            "\tLuminous Terraglass Collecting: 1\n",
            "\tDowsing for Ancient Runestones: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "Counter({'Eryndor Thorne': 3, 'Eira Shadowglow': 3, 'Lyrieth Starweaver': 2, 'Lyriyth Blackwood': 1, 'Lyrietha Flynn': 1, 'Kaelin Darkshadow': 1, 'Eiraethon': 1, 'Elyriana Starweaver': 1, 'Lyriquin Darkshadow': 1, 'Eiravyn Starweaver': 1, 'Lyriath Moonwhisper': 1, 'Elyriath Starweaver': 1, 'Elyriana': 1, 'Eriolyn Starweaver': 1, 'Elyriana Emberwood': 1})\n",
            "\tEryndor Thorne: 3\n",
            "\tEira Shadowglow: 3\n",
            "\tLyriyth Blackwood: 1\n",
            "\tLyrietha Flynn: 1\n",
            "\tKaelin Darkshadow: 1\n",
            "\tEiraethon: 1\n",
            "\tElyriana Starweaver: 1\n",
            "\tLyrieth Starweaver: 2\n",
            "\tLyriquin Darkshadow: 1\n",
            "\tEiravyn Starweaver: 1\n",
            "\tLyriath Moonwhisper: 1\n",
            "\tElyriath Starweaver: 1\n",
            "\tElyriana: 1\n",
            "\tEriolyn Starweaver: 1\n",
            "\tElyriana Emberwood: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "Counter({'Mythkeeper': 3, 'Mythweaver': 3, 'Dreamweaver': 2, 'Shadow Weaver': 2, 'Arcane Cartographer': 2, 'Dreamwalker': 1, 'Mythsmith': 1, 'Moonlit Cartographer': 1, 'Sky Pirate Captain': 1, 'Clockwork Engineer': 1, 'Moonwhisper Cartographer': 1, 'Mythocrat': 1, 'Mythologist': 1})\n",
            "\tMythkeeper: 3\n",
            "\tDreamwalker: 1\n",
            "\tDreamweaver: 2\n",
            "\tMythsmith: 1\n",
            "\tMoonlit Cartographer: 1\n",
            "\tSky Pirate Captain: 1\n",
            "\tClockwork Engineer: 1\n",
            "\tMythweaver: 3\n",
            "\tMoonwhisper Cartographer: 1\n",
            "\tMythocrat: 1\n",
            "\tShadow Weaver: 2\n",
            "\tMythologist: 1\n",
            "\tArcane Cartographer: 2\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "Counter({'Stardust Cartography': 2, 'Stargazing Cartography': 2, 'Moonwhispering': 2, 'Starlight Cartography': 1, 'Starlight Orienteering': 1, 'Astronomic Cartography': 1, 'Moonlit Calligraphy': 1, 'Mythical Cartography': 1, '\"Moonwhispering\"': 1, 'Astrocartography': 1, 'Mythweaving': 1, 'Stardust cartography': 1, 'Starmapping': 1, 'Shadow Gardening': 1, 'Starglassblowing': 1, 'Celestial Cartography': 1, 'Mythrilworking': 1})\n",
            "\tStarlight Cartography: 1\n",
            "\tStarlight Orienteering: 1\n",
            "\tStardust Cartography: 2\n",
            "\tStargazing Cartography: 2\n",
            "\tAstronomic Cartography: 1\n",
            "\tMoonlit Calligraphy: 1\n",
            "\tMoonwhispering: 2\n",
            "\tMythical Cartography: 1\n",
            "\t\"Moonwhispering\": 1\n",
            "\tAstrocartography: 1\n",
            "\tMythweaving: 1\n",
            "\tStardust cartography: 1\n",
            "\tStarmapping: 1\n",
            "\tShadow Gardening: 1\n",
            "\tStarglassblowing: 1\n",
            "\tCelestial Cartography: 1\n",
            "\tMythrilworking: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "Counter({'Eiraethon': 4, 'Elyriana': 3, 'Kaelorin': 2, 'Eiraen Darkshadow': 1, 'Eiraeth Oakshadow': 1, 'Elyrianna': 1, 'Eiraeth Winterbourne': 1, 'Xylaraeth': 1, 'Eira Shadowglow': 1, 'Eryndor Thorne': 1, 'Kaelorvyn': 1, 'Eriolyn.': 1, 'Kaelith Sunshadow': 1, 'Elyriana.': 1})\n",
            "\tEiraen Darkshadow: 1\n",
            "\tEiraeth Oakshadow: 1\n",
            "\tElyrianna: 1\n",
            "\tEiraeth Winterbourne: 1\n",
            "\tKaelorin: 2\n",
            "\tXylaraeth: 1\n",
            "\tEiraethon: 4\n",
            "\tEira Shadowglow: 1\n",
            "\tElyriana: 3\n",
            "\tEryndor Thorne: 1\n",
            "\tKaelorvyn: 1\n",
            "\tEriolyn.: 1\n",
            "\tKaelith Sunshadow: 1\n",
            "\tElyriana.: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "Counter({'Shadow Weaver': 15, 'Shadow Weaver.': 2, 'Windrunner': 1, 'Moonwhisper Apothecary': 1, 'Dreamweaver': 1})\n",
            "\tShadow Weaver: 15\n",
            "\tWindrunner: 1\n",
            "\tMoonwhisper Apothecary: 1\n",
            "\tShadow Weaver.: 2\n",
            "\tDreamweaver: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "Counter({'Moonlit Cartography': 3, 'Shadow Weaving': 3, 'Shadowcrafting': 2, 'Moonstone carving.': 2, 'Stellar Cartography': 1, 'Astrocartography': 1, 'Dreamweaving': 1, 'Dreamwalking': 1, 'Celestial Cartography': 1, 'Shadow weaving.': 1, 'Stardust Cartography': 1, 'Dreamweaving.': 1, 'Moonwhisper Weaving': 1, 'Astral Cartography': 1})\n",
            "\tMoonlit Cartography: 3\n",
            "\tShadowcrafting: 2\n",
            "\tStellar Cartography: 1\n",
            "\tAstrocartography: 1\n",
            "\tDreamweaving: 1\n",
            "\tDreamwalking: 1\n",
            "\tShadow Weaving: 3\n",
            "\tMoonstone carving.: 2\n",
            "\tCelestial Cartography: 1\n",
            "\tShadow weaving.: 1\n",
            "\tStardust Cartography: 1\n",
            "\tDreamweaving.: 1\n",
            "\tMoonwhisper Weaving: 1\n",
            "\tAstral Cartography: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "Counter({'Eldrin Stormweaver': 5, 'Eliorn Stardust': 1, 'Eldrin Moonwhisper': 1, 'Eliadora Stormwhisper': 1, 'Elderwine Silverglow': 1, 'Elara Moonwhisper': 1, 'Elowen Moonwhisper': 1, 'Elowen Stormweaver': 1, 'Lyrina Moonwhisper': 1, 'Thalorien Stormwhisper': 1, 'Elorin Stormweaver': 1, 'Eldric Shadowglow': 1, 'Elowen Silverglow': 1, 'Eliora Stormweaver': 1, 'Eliana Starweaver': 1, 'Elowen Starweaver': 1})\n",
            "\tEldrin Stormweaver: 5\n",
            "\tEliorn Stardust: 1\n",
            "\tEldrin Moonwhisper: 1\n",
            "\tEliadora Stormwhisper: 1\n",
            "\tElderwine Silverglow: 1\n",
            "\tElara Moonwhisper: 1\n",
            "\tElowen Moonwhisper: 1\n",
            "\tElowen Stormweaver: 1\n",
            "\tLyrina Moonwhisper: 1\n",
            "\tThalorien Stormwhisper: 1\n",
            "\tElorin Stormweaver: 1\n",
            "\tEldric Shadowglow: 1\n",
            "\tElowen Silverglow: 1\n",
            "\tEliora Stormweaver: 1\n",
            "\tEliana Starweaver: 1\n",
            "\tElowen Starweaver: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "Counter({'Dragon Tamer': 9, 'Enchanter': 4, 'Wizard': 3, 'Blacksmith': 2, 'Enchantress': 1, 'Dragoon': 1})\n",
            "\tEnchantress: 1\n",
            "\tEnchanter: 4\n",
            "\tDragon Tamer: 9\n",
            "\tWizard: 3\n",
            "\tBlacksmith: 2\n",
            "\tDragoon: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "Counter({'Dragon Painting': 4, 'Dragon Riding': 2, 'Magic Card Crafting': 2, 'Soulweaving': 1, 'Dragon Watching': 1, 'Collecting Ancient Scrolls': 1, 'Magic Spell Crafting': 1, 'Dragonriding': 1, 'Spellcrafting': 1, 'Dragon Training': 1, 'Wizardry Dueling': 1, 'Dragon Taming': 1, 'Sword Making': 1, 'DragonSpotting': 1, 'World Mapping': 1})\n",
            "\tDragon Riding: 2\n",
            "\tMagic Card Crafting: 2\n",
            "\tSoulweaving: 1\n",
            "\tDragon Watching: 1\n",
            "\tDragon Painting: 4\n",
            "\tCollecting Ancient Scrolls: 1\n",
            "\tMagic Spell Crafting: 1\n",
            "\tDragonriding: 1\n",
            "\tSpellcrafting: 1\n",
            "\tDragon Training: 1\n",
            "\tWizardry Dueling: 1\n",
            "\tDragon Taming: 1\n",
            "\tSword Making: 1\n",
            "\tDragonSpotting: 1\n",
            "\tWorld Mapping: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So, what can we do to make our names more original?**\n",
        "\n",
        "The author of this notebook would say that the problem is not just in the lack of diversity in names and occupations. They are also pterry much generic and non-relatable. What on the Earth are Shadowcrafting and\tStellar Cartography?..\n",
        "\n",
        "And if an LLM cannot produce anything relatable on its own, references may help. So, let's ask the LLM first to come up with a reference from real-world culture and then create a characer based on it. Let's see if that helps:"
      ],
      "metadata": {
        "id": "7imz7CfN1cAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = answer_with_llm(\n",
        "    \"\"\"Your task will be to create a description of an original fantasy character: name, occupation, and hobby.\n",
        "    But the characters you create should be diverse and original.\n",
        "    To build such a character you'll leverage real-world cultural references.\n",
        "    You'll choose a real historical cultures or cultures represented in fantasy literature.\n",
        "    You'll create a name, an occupation, and a hobby that would be appropriate in this culture.\n",
        "    You'll tweak them a bit to make them original.\n",
        "    Output everything in the following format:\n",
        "\n",
        "    #CHOSEN_CULTURE:\n",
        "    <chosen_culture>\n",
        "\n",
        "    #NAME: <name>\n",
        "\n",
        "    #OCCUPATION: <occupation>\n",
        "\n",
        "    #HOBBY: <hobby>\"\"\",\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    temperature=1\n",
        "    )\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc0O2ATRuIdt",
        "outputId": "b4e03929-3ee1-4c53-9db5-19826df76a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'll create a character drawing from various cultural influences.\n",
            "\n",
            "#CHOOSE_CULTURE: Xhosa (from South Africa)\n",
            "\n",
            "#NAME: Mantiwe \"Mae\" Ntaba\n",
            "\n",
            "#OCCUPATION: Makershop Manager - responsible for crafting intricate wooden\n",
            "carvings, now running a small makerspace where fellow artisans share techniques\n",
            "and collaborate on innovative projects.\n",
            "\n",
            "#HOBBY: Combining her passion for traditional Xhosa designs with artisanal\n",
            "coffee roasting, Mae experiments with unique blends, infusing them with African\n",
            "botanicals like yohimbe and red bush tea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like not only the names became more diverse, but also the occupations are now somewhat more relatable."
      ],
      "metadata": {
        "id": "BFT-EMco2POe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And, by the way, there is another funny way of making the generation more diverse, which very much looks like an exploit. Let's just add a 16-character **random seed** to the prompt and look what happens."
      ],
      "metadata": {
        "id": "uSWlig8KYGHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "n_trials = 20\n",
        "prompts = [\n",
        "    \"\"\"Suggest a name for a fantasy character. Only output the name.\"\"\",\n",
        "    \"\"\"Suggest an occupation for a fantasy character. Only output the occupation name.\"\"\",\n",
        "    \"\"\"Suggest an hobby for a fantasy character. Only output the hobby name.\"\"\"\n",
        "]\n",
        "models = [\n",
        "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "    \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "    \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
        "    \"Qwen/Qwen2.5-32B-Instruct\"\n",
        "]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model in models:\n",
        "    for prompt in prompts:\n",
        "        results[(model, prompt)] = []\n",
        "        print(f\"Processing:\\n\\tmodel: {model}\\n\\tprompt: {prompt}\")\n",
        "        for _ in tqdm(range(n_trials)):\n",
        "            answer = answer_with_llm(prompt+f\"\"\"\\nRandom_seed={\n",
        "                ''.join(random.choice(string.ascii_letters) for _ in range(16))\n",
        "            }\"\"\", model=model, temperature=1)\n",
        "            results[(model, prompt)].append(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Bd3q--WYpg",
        "outputId": "98d566aa-90ab-4b6b-a614-53e2cab77305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:06<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest a name for a fantasy character. Only output the name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:13<00:00,  3.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest an occupation for a fantasy character. Only output the occupation name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:08<00:00,  3.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing:\n",
            "\tmodel: Qwen/Qwen2.5-32B-Instruct\n",
            "\tprompt: Suggest an hobby for a fantasy character. Only output the hobby name.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:58<00:00,  2.93s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "for key, value in results.items():\n",
        "    print(f\"model = {key[0]}\\nprompt = {key[1]}:\\n\")\n",
        "    for k, v in Counter(value).items():\n",
        "        print(f\"\\t{k}: {v}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddDRRcFaXFsn",
        "outputId": "e32c779b-736c-4060-8457-4862818c4dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tKaelith Sunshadow: 6\n",
            "\tKaelin Valtoriel: 1\n",
            "\tLyra Fÿnris: 1\n",
            "\tEirlys Vylara: 1\n",
            "\tXylarae Thorneblackwood: 1\n",
            "\tLyraeleth Moonwhisper: 1\n",
            "\tLythariel \"Lys\" Darqsol: 1\n",
            "\tLyra Flynnshadow: 1\n",
            "\tHizjiyum Rynx: 1\n",
            "\tLythariel Vexarath: 1\n",
            "\tEirlys Eldrid: 1\n",
            "\tZhilakai Vyravys: 1\n",
            "\tKaelin Darkhaven: 1\n",
            "\tWystan Thorne: 1\n",
            "\tLyra Fflore: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tDreamweaver: 2\n",
            "\tMoonwhisper Cartographer: 3\n",
            "\tClockwork Engineer: 1\n",
            "\tCryptomancer: 2\n",
            "\tWild Hunt Tracker: 1\n",
            "\tArcane Cartographer: 1\n",
            "\tCourier of the Windswept Isles: 1\n",
            "\tClockwork Artificer: 1\n",
            "\tMoonwhisper Skinner of Gilded Sheets: 1\n",
            "\tMoonwhisper Ariadelfi Weaver of Lunar Fates: 1\n",
            "\tEchokeeper of the Forgotten Library: 1\n",
            "\tCryptkeeper's Apprentice: 1\n",
            "\tGuildhealer Master: 1\n",
            "\tMoonwhisper Cartologist: 1\n",
            "\tMoonwhisper Dreamweaver: 1\n",
            "\tShadow Weaver: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-8B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tWhispercraft: 1\n",
            "\tMoonwatching.: 1\n",
            "\tAstral Cartography: 1\n",
            "\tMythril Scale Collecting: 1\n",
            "\tEnvironmental gardening of luminescent mushrooms.: 1\n",
            "\tMythril Collection</squirrel_runs>: 1\n",
            "\tGardening of rare mystical blooms: 1\n",
            "\tWhisperwood Lichenology: 1\n",
            "\tLuminous Glasssculpting: 1\n",
            "\tMythic cartography: 1\n",
            "\tLuminous Landscape Designing: 1\n",
            "\tLuminari Glassblowing: 1\n",
            "\tLuminous Tapestry Weaving: 1\n",
            "\tFortune Telling with Runed Stones: 1\n",
            "\tMythweaving: 1\n",
            "\tMythril Inlay Crafting: 1\n",
            "\tFeywood Carving: 1\n",
            "\tClockwork Insectry: 1\n",
            "\tMythic Cartography: 1\n",
            "\tCrystal growing: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\t\"Eira Shadowglow\": 1\n",
            "\tXylaraeth: 3\n",
            "\tKaidaira Elyri: 1\n",
            "\tLyriqrin Valtor: 1\n",
            "\tKaelara Moonwhisper: 1\n",
            "\tEiravyn: 1\n",
            "\tKaelin Valtor: 2\n",
            "\tKaelith Sunshadow: 2\n",
            "\tLysandriathiel: 1\n",
            "\tLyrieth νεφοκ<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Would you like me to suggest another name?: 1\n",
            "\tKaelin Darkshadow: 3\n",
            "\tThoroldir Starweaver: 1\n",
            "\tLyrietha Blackwood: 1\n",
            "\tKhraenvel: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tMythographer: 6\n",
            "\tShadow Weaver: 1\n",
            "\tMythkeeper: 1\n",
            "\tMoonlit Cartographer: 1\n",
            "\tIlluminator: 1\n",
            "\tArcane Cartographer: 1\n",
            "\tDreamweaver: 1\n",
            "\tWind Dancer: 1\n",
            "\tDreamwalker: 2\n",
            "\tMythologist: 2\n",
            "\tChronicler: 1\n",
            "\tChronicler of Lost Lore: 1\n",
            "\tMythical Cartographer: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-70B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tStardust Cartography: 1\n",
            "\tAstral Cartography: 1\n",
            "\tAstrocartography: 1\n",
            "\tMythril Crafting: 3\n",
            "\tMythril Calligraphy: 1\n",
            "\tMythical Botany: 2\n",
            "\tMoonlit Botany: 1\n",
            "\tMythril Engraving: 4\n",
            "\tAstronomical Cartography: 1\n",
            "\tStarglass Crafting: 2\n",
            "\tStargazing: 1\n",
            "\tMythical Cartography: 1\n",
            "\tLuminous Ink Calligraphy: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tEryndor Thorne: 1\n",
            "\tZhilakarixys: 1\n",
            "\tAethonixa: 1\n",
            "\tZhilakarion: 1\n",
            "\tZhilakai: 3\n",
            "\tXylaraeth: 2\n",
            "\tYlrineth Darkwalker: 1\n",
            "\tZhrakayla: 1\n",
            "\tZhilakael: 1\n",
            "\tKhalarysta: 1\n",
            "\tKaelor Vyrathor: 1\n",
            "\tKaelorin Valthorne.: 1\n",
            "\tXylaraetha: 1\n",
            "\tXylaraeth Darkshadow: 1\n",
            "\tKorvethys: 1\n",
            "\tEiravyn: 1\n",
            "\tZhilak Darksong: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tShadow Weaver: 7\n",
            "\tArcane Cartographer: 1\n",
            "\tGlamour Weaver: 1\n",
            "\tMoonstone Diviner: 1\n",
            "\tShadow Sentinel: 1\n",
            "\tGolemcraft Artisan: 1\n",
            "\tClockwork Artisan: 1\n",
            "\tMythweaver: 1\n",
            "\tMirrorwalker.: 1\n",
            "\tWindrunner: 1\n",
            "\tMistdancer.: 1\n",
            "\tMoonstone Engraver: 1\n",
            "\tClockwork Engineer: 1\n",
            "\tGolemcraft Engineer: 1\n",
            "\n",
            "model = meta-llama/Meta-Llama-3.1-405B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tShadow Puppetry: 2\n",
            "\tShadow puppetry.: 1\n",
            "\t\"Glimmer gardening\": 1\n",
            "\tDragon scale collecting.: 2\n",
            "\tCrystal resonance tuning: 1\n",
            "\tShadow Weaving: 2\n",
            "\tStardust Collecting: 1\n",
            "\tAstronomancy: 1\n",
            "\tShadow Puppetry.: 1\n",
            "\tStargazing: 2\n",
            "\tCelestial Cartography: 1\n",
            "\tShadow puppetry: 1\n",
            "\tAstral Cartography: 1\n",
            "\tShadow-weaving.: 1\n",
            "\tCrystal Resonance Tuning.: 1\n",
            "\tStarlight Cartography: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest a name for a fantasy character. Only output the name.:\n",
            "\n",
            "\tElowen Moonwhisper: 1\n",
            "\tLirael Silverblind: 1\n",
            "\tFelix Stormweaver: 1\n",
            "\tLyrin Frostwind: 1\n",
            "\tThalion Windsong: 1\n",
            "\tEldric Stormweaver: 2\n",
            "\tEldrin Silverglow: 1\n",
            "\tLorin Moonwhisper: 1\n",
            "\tElowen Silverfoot: 1\n",
            "\tEldrin Silvervein: 1\n",
            "\tLysandra Stormweaver: 2\n",
            "\tElowen Stormweaver: 1\n",
            "\tEldrin Moonwhisper: 1\n",
            "\tLyra Silverwhisper: 1\n",
            "\tLysandra Moonwhisper: 2\n",
            "\tEldrin Stormweaver: 1\n",
            "\tEliora Stardust: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest an occupation for a fantasy character. Only output the occupation name.:\n",
            "\n",
            "\tBlacksmith: 2\n",
            "\tArcane Librarian: 4\n",
            "\tDragon Tamer: 5\n",
            "\tEnchanter: 4\n",
            "\tEnchantress: 1\n",
            "\tArmorer: 1\n",
            "\tDragon Trainer: 1\n",
            "\tWizard: 1\n",
            "\tArtificer: 1\n",
            "\n",
            "model = Qwen/Qwen2.5-32B-Instruct\n",
            "prompt = Suggest an hobby for a fantasy character. Only output the hobby name.:\n",
            "\n",
            "\tDragon Riding: 5\n",
            "\tMagic Brewing: 1\n",
            "\tDragon training: 1\n",
            "\tMagic Card Crafting: 3\n",
            "\tCoin Collecting: 1\n",
            "\tDragonriding: 1\n",
            "\tDragon Sketching: 1\n",
            "\tDragon Whispering: 1\n",
            "\tSorcery: 1\n",
            "\tDragon Painting: 1\n",
            "\tDragon Training: 2\n",
            "\tMagic Book Binding: 1\n",
            "\tMagic Card Dueling: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quite funnily, the outputs really become somewhat less predictable."
      ],
      "metadata": {
        "id": "l2Z5Bjv_Y6ke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2. Frequency penalty\n",
        "\n",
        "Another inference parameter of the OpenAI and Nebius API is `frequency_penalty`. It may be between -2 and 2, and if you set it to a positive value, it will discourage the LLM from repeating tokens.\n",
        "\n",
        "If you want to understand how it works, imagine that a LLM outputs a token `\"You\"`. After that, each time it generates a new token, a number will be subtracted from the logit of \"You\", making this token less probable. The penalty stacks with each new instance of \"You\", eventually making its generation very improbable.\n",
        "\n",
        "We suggest you to explore this parameter by creating a situation where an LLM is explicitly prompted to generate something repetitively. For example, you can use the following request:\n",
        "\n",
        "```\n",
        "\"\"\"List 15 reasons to use Llama models.\n",
        "Each item in the list should start with 'Llama models are'\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "But we encourage you to be creative and to come up with your own prompt!\n",
        "\n",
        "Now, try this prompt with `frequency_penalty=1` and `frequency_penalty=2`. We suggets using Llama-3.1-8B. What happens with the repeated terms?"
      ],
      "metadata": {
        "id": "w5NgC9mskLnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR EXPERIMENTS HERE>"
      ],
      "metadata": {
        "id": "HSDD6jBpnq1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**"
      ],
      "metadata": {
        "id": "_nqJ79pUWYMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's query the LLM with the suggested prompt:"
      ],
      "metadata": {
        "id": "r-o1xPKRnuaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = answer_with_llm(\"\"\"List 15 reasons to use Llama models.\n",
        "Each item in the list should start with 'Llama models are'\n",
        "\"\"\",\n",
        "                         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "                         frequency_penalty=1)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q8QiY-tlakE",
        "outputId": "63455127-e4b9-4d82-efed-6d82d9bd56dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 15 reasons to use Llama models:\n",
            "\n",
            "1. Llama models are highly efficient in processing and generating large amounts\n",
            "of text data.\n",
            "2. Llama models are capable of understanding and responding to complex natural\n",
            "language queries.\n",
            "3. Llama models are trained on a vast amount of text data, making them\n",
            "knowledgeable in various subjects.\n",
            "4. Llama models are able to learn from their interactions and improve over time\n",
            "through machine learning algorithms.\n",
            "5. Llama models are highly scalable, allowing for easy integration with various\n",
            "applications and systems.\n",
            "6. Llama models are able to generate human-like responses, making them suitable\n",
            "for customer service chatbots.\n",
            "7. Llama models are fast at generating responses, even with complex or\n",
            "open-ended questions.\n",
            "8. Llama models can be fine-tuned for specific tasks or domains, such as\n",
            "medical or financial applications.\n",
            "9. Llama models can handle multiple languages and dialects, facilitating global\n",
            "communication and collaboration.\n",
            "10. LlavaeLama Models Are Highly Secure: They process sensitive information\n",
            "securely without storing it locally.\n",
            "\n",
            "11.LLama Models Are Versatile: They can be used in a variety of applications\n",
            "such as content generation,\n",
            "12.LLama Models Are Capable Of Emulating Human Conversations And Interactions\n",
            "13.LLama Models Can Be Used For Language Translation And Interpretation\n",
            "14.LlammaModelsAreCost-Effective: They reduce the need for human labor in tasks\n",
            "such as data entry or customer support\n",
            "15.Llamamodelsareabletocompetewithhumanintelligenceinmanydomains\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = answer_with_llm(\"\"\"List 15 reasons to use Llama models.\n",
        "Each item in the list should start with 'Llama models are'\n",
        "\"\"\",\n",
        "                         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "                         frequency_penalty=2)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjNc8u0TmGOO",
        "outputId": "6451abf5-2692-46a0-f326-2f0d360f0192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 15 reasons to use Llama models:\n",
            "\n",
            "1. Llama models are highly efficient in processing and responding to large\n",
            "amounts of text data.\n",
            "2. Llama models are capable of understanding context and nuances in language,\n",
            "enabling more accurate responses.\n",
            "3. Llama models are trained on diverse datasets, allowing them to provide\n",
            "insights across various domains.\n",
            "4. Llama models are able to generate human-like text that is coherent and\n",
            "engaging.\n",
            "5. Llama models can assist with tasks such as content creation, summarization,\n",
            "and translation at scale.\n",
            "6. Llava Models can be used for sentiment analysis by identifying emotions\n",
            "expressed through language patterns\n",
            "7.LLama Models Are Capable Of Generating Unique Content By Combining Different\n",
            "Sources Of Information And Perspectives\n",
            "8.LLama Models Are Highly Customizable Allowing Users To Tailor Their Output To\n",
            "Suit Specific Business Or Personal Needs\n",
            "9.Llamas Can Assist In Data Collection By Asking Follow-Up Questions Based On\n",
            "User Responses\n",
            "10 llamas Can Be Integrated Into A Variety Of Applications Such As Chatbots\n",
            "Virtual Assistants And More\n",
            "11 llama Provides Real-Time Response Which Allows For Quick Adaptation To\n",
            "Changing Situations\n",
            "12 Lama's Ability To Understand Idioms Jokes And Sarcasm Makes It A Valuable\n",
            "Tool For Communication Across Cultural Boundaries\n",
            "13 lllamas Offer An Objective Perspective Free From Biases That Humans Often\n",
            "Bring With Them When Interpreting Information\n",
            "14 LLAMA'S USE OF NATURAL LANGUAGE PROCESSING ALLOWS IT TO LEARN FROM USER\n",
            "FEEDBACK AND IMPROVE OVER TIME\n",
            "15.llama Is Continuously Learning – The Model Updates Its Knowledge Base\n",
            "Automatically Through Machine Learning Algorithms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, the LLM tries to accommodate both demands by going uppercase or lowercase (those are different tokens!), introducing typos, sometimes even breaking words with spaces or merging words together."
      ],
      "metadata": {
        "id": "SDc-6g1mnzX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3. Uncertainty in generation\n",
        "\n",
        "In essence, an LLM is a classifier: at each generation step, it selects the next token from all possible tokens in its vocabulary by predicting their probabilities. For a classifier, it is sometimes useful to measure the **uncertainty** of its classification.\n",
        "\n",
        "What does uncertainty mean and why is it useful?\n",
        "\n",
        "Imagine that we're solving a Q&A task where the LLM needs to choose between answer options `A`, `B`, `C`, and `D`.\n",
        "\n",
        "Let's examine the following three distributions of probabilities that the LLM might assign to the tokens `A`, `B`, `C`, and `D`:"
      ],
      "metadata": {
        "id": "FR1Oyf2zJ4Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "\n",
        "# Define tokens\n",
        "tokens = [\"A\", \"B\", \"C\", \"D\"]\n",
        "\n",
        "# Define three probability distributions\n",
        "uniform = np.array([0.25, 0.25, 0.25, 0.25])  # Total uncertainty\n",
        "uncertain = np.array([0.1, 0.2, 0.3, 0.4])   # Some certainty, but still uncertain\n",
        "certain = np.array([0.0, 0.0, 0.0, 1.0])      # Full certainty\n",
        "\n",
        "# Define a function to compute entropy manually\n",
        "def manual_entropy(probs):\n",
        "    return -np.sum(probs * np.log2(probs + 1e-9))  # Small constant to avoid log(0)\n",
        "\n",
        "entropies = {\n",
        "    \"Uniform\": compute_entropy(uniform),\n",
        "    \"Uncertain\": compute_entropy(uncertain),\n",
        "    \"Certain\": compute_entropy(certain)\n",
        "}\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
        "\n",
        "# Define distributions and titles\n",
        "distributions = [uniform, uncertain, certain]\n",
        "titles = [\n",
        "    f\"Uniform Distribution\\nEntropy: {entropies['Uniform']:.2f}\",\n",
        "    f\"Uncertain Distribution\\nEntropy: {entropies['Uncertain']:.2f}\",\n",
        "    f\"Highly Certain Distribution\\nEntropy: {entropies['Certain']:.2f}\"\n",
        "]\n",
        "\n",
        "# Plot each distribution\n",
        "for ax, dist, title in zip(axes, distributions, titles):\n",
        "    ax.bar(tokens, dist, color='royalblue')\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Tokens\")\n",
        "    ax.set_ylabel(\"Probability\")\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "4iGoKbEwSPrZ",
        "outputId": "f57af69d-962e-489b-a0af-c9641044d22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The rightmost distribution represents full certainty: the model is confident that the `D` is the right answer.\n",
        "* The central distribution favors `D` but considers other options as likely. This situation is problematic. It might indicate a potential error or even a hallucination.\n",
        "* The leftmost distribution reflects total uncertainty—the model has no clear preference and does not know what to choose.\n",
        "\n",
        "With probabilities, uncertainty is often assessed using **entropy**. If an LLM predicts probabilities $p = (p_1,\\ldots,p_V)$ for tokens $x_1,\\ldots,x_V$ from the vocabulary, entropy is calculated as:\n",
        "\n",
        "$$entropy(p) = -\\sum_{i=1}^Vp_i\\log{p_i}$$\n",
        "\n",
        "It's non-negative. If the LLM predicts a single token with 100% certainty, the entropy is 0. Otherwise, the larger the entropy is, the closer is the distribution to uniform (leftmost picture) and terminal uncertainty. Above each picture, you can check its entropy values.\n",
        "\n",
        "When using an API, we unfortunately cannot directly calculate entropy because the API only provides the top 5 log probabilities. However, we can still infer uncertainty by:\n",
        "\n",
        "* Checking the highest probability: If it is close to 1, the uncertainty is low.\n",
        "* Comparing the top-5 probabilities: If the highest probability significantly outweighs the others—like in the leftmost picture below—the model is confident in its choice.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=12k5EFzMZAcHntuJZBZwbm6NKqJZ1OF3l\" width=600 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "P8yEbfmMSwRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task will be to explore the connection between uncertainty and in-context hallucination. The term \"In-context hallucinations\" refers to situations when an LLM’s answers are unfaithful to the context provided in a prompt.\n",
        "\n",
        "To illustrate this, let's create a synthetic context—a list of fictional rulers along with their years of reign. Then, we'll ask the LLM to provide the years of reign for one of them."
      ],
      "metadata": {
        "id": "UlVPipyfTmfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def int_to_roman(num):\n",
        "    val = [\n",
        "        1000, 900, 500, 400,\n",
        "        100, 90, 50, 40,\n",
        "        10, 9, 5, 4,\n",
        "        1\n",
        "    ]\n",
        "    syb = [\n",
        "        \"M\", \"CM\", \"D\", \"CD\",\n",
        "        \"C\", \"XC\", \"L\", \"XL\",\n",
        "        \"X\", \"IX\", \"V\", \"IV\",\n",
        "        \"I\"\n",
        "    ]\n",
        "    roman_num = ''\n",
        "    i = 0\n",
        "    while num > 0:\n",
        "        for _ in range(num // val[i]):\n",
        "            roman_num += syb[i]\n",
        "            num -= val[i]\n",
        "        i += 1\n",
        "    return roman_num\n",
        "\n",
        "def generate_monarchs(start_year=793, n_monarchs=100):\n",
        "    names = [\n",
        "        \"Vaelith\", \"Eldric\", \"Seraphis\", \"Altheryn\", \"Ysara\", \"Thalion\", \"Miren\", \"Zephiron\", \"Caldris\", \"Velmora\",\n",
        "        \"Eryndor\", \"Sylvara\", \"Draethor\", \"Ilvanya\", \"Tareth\", \"Lyssandre\", \"Veylan\", \"Morveth\", \"Xandrel\", \"Lyra\"\n",
        "    ]\n",
        "\n",
        "    numerics = {name: 0 for name in names}  # Track numerics for each name\n",
        "    year = start_year\n",
        "\n",
        "    just_had_interregnum = False\n",
        "\n",
        "    monarch_list = []\n",
        "\n",
        "    for _ in range(n_monarchs):\n",
        "\n",
        "        name = random.choice(names)\n",
        "        numerics[name] += 1\n",
        "        reign_length = random.randint(7, 20)  # Random reign length\n",
        "        monarch_list.append(f\"{name} {int_to_roman(numerics[name])}, {year}-{year + reign_length}\")\n",
        "        year += reign_length\n",
        "        just_had_interregnum = False\n",
        "\n",
        "    return(monarch_list)\n"
      ],
      "metadata": {
        "id": "zvZ26ykntAYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monarch_list = generate_monarchs(n_monarchs=2500)"
      ],
      "metadata": {
        "id": "OrF6ruXEtAaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monarch_list[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a61bymTZtAcL",
        "outputId": "19540829-437c-4414-9718-39db2e677ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Velmora CXXIII, 34610-34628',\n",
              " 'Veylan CXXIX, 34628-34636',\n",
              " 'Eryndor CXX, 34636-34654',\n",
              " 'Altheryn CXXIV, 34654-34668',\n",
              " 'Lyra CXXII, 34668-34685',\n",
              " 'Lyra CXXIII, 34685-34704',\n",
              " 'Vaelith CXVI, 34704-34715',\n",
              " 'Caldris CXVIII, 34715-34725',\n",
              " 'Xandrel CXXI, 34725-34745',\n",
              " 'Seraphis CXXVII, 34745-34753']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a list of 1000 rulers, **Llama-3.1-8B** will be quite good at answering our questions (try this!). But when the list has 5000 entries, things get worse.\n",
        "\n",
        "Create a random sample of 10 rulers (not 10 first ones and not 10 last ones; please take a random subsample; otherwise you may get different and better results than you're suuposed to). Run `answer_with_logprobs` with `temperature=0.6` and the prompt\n",
        "\n",
        "```\n",
        "monarch_prompt = \"Below is the list of monarchs of the land of Xu and their years of reign.\\n\"\n",
        "\n",
        "monarch_prompt += \"\\n\".join(monarch_list)\n",
        "\n",
        "monarch_prompt += \"\"\"\\nUsing this list, give the years of reign of {test_monarch}.\n",
        "Only give the years in the format <start_year>-<end_year>\"\"\"\n",
        "```\n",
        "\n",
        "Print logprobs using `logprobs_to_table` for several correct and several incorrect answers. If there are no correct answers, rerun the experiment and/or increase the test sample. Investigate the table. Is the LLM more confident when given correct answers?"
      ],
      "metadata": {
        "id": "l60SmBurUNQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR EXPERIMENTS HERE>"
      ],
      "metadata": {
        "id": "Ry0If7rDV0XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**\n",
        "\n",
        "Let's tun the experiment"
      ],
      "metadata": {
        "id": "k724wOuXWcmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_cases = np.random.choice(monarch_list, size=10, replace=False)\n",
        "test_cases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kK1qwZu72WZ",
        "outputId": "63543585-059e-4391-e7b3-790ba05c0ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Draethor XLIII, 11872-11887', 'Sylvara CV, 30221-30233',\n",
              "       'Lyssandre XXIII, 6446-6460', 'Thalion LVIII, 15364-15372',\n",
              "       'Ilvanya XXXIV, 9903-9911', 'Thalion CII, 26079-26096',\n",
              "       'Thalion XLIII, 10518-10534', 'Lyra XXXIV, 10193-10201',\n",
              "       'Eryndor XCVI, 26408-26424', 'Sylvara XII, 4419-4428'],\n",
              "      dtype='<U31')"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monarch_prompt = \"Below is the list of monarchs of the land of Xu and their years of reign.\\n\"\n",
        "\n",
        "monarch_prompt += \"\\n\".join(monarch_list)\n",
        "\n",
        "monarch_prompt += \"\"\"\\nUsing this list, give the years of reign of {test_monarch}.\n",
        "Only give the years in the format <start_year>-<end_year>\"\"\"\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, test_case in enumerate(test_cases):\n",
        "    test_monarch, test_years = test_case.split(\", \")\n",
        "    print(f\"Test case no. {i}: {test_monarch}\")\n",
        "    result = answer_with_logprobs(\n",
        "        monarch_prompt.format(test_monarch=test_monarch),\n",
        "                         model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
        "    predicted_years = result.choices[0].message.content.strip()\n",
        "    results.append(result)\n",
        "    print(f\"\"\"True years: {test_years},\\t Predicted years: {predicted_years}\\t {\n",
        "        \"Correct\" if test_years == predicted_years else \"Incorrect\"\n",
        "    }\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvkhVEDtAJnR",
        "outputId": "477dc03a-6b4b-4154-bb5c-5d75c5c451f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test case no. 0: Draethor XLIII\n",
            "True years: 11872-11887,\t Predicted years: 11872-11887\t Correct\n",
            "Test case no. 1: Sylvara CV\n",
            "True years: 30221-30233,\t Predicted years: No information is provided in the list regarding Sylvara CV.\t Incorrect\n",
            "Test case no. 2: Lyssandre XXIII\n",
            "True years: 6446-6460,\t Predicted years: There is no Lyssandre XXIII in the list.\t Incorrect\n",
            "Test case no. 3: Thalion LVIII\n",
            "True years: 15364-15372,\t Predicted years: Thalion LVIII reigned from 16736-16755.\t Incorrect\n",
            "Test case no. 4: Ilvanya XXXIV\n",
            "True years: 9903-9911,\t Predicted years: 9903-9911\t Correct\n",
            "Test case no. 5: Thalion CII\n",
            "True years: 26079-26096,\t Predicted years: 2088-2106\t Incorrect\n",
            "Test case no. 6: Thalion XLIII\n",
            "True years: 10518-10534,\t Predicted years: Unfortunately, Thalion XLIII is not present in the list.\t Incorrect\n",
            "Test case no. 7: Lyra XXXIV\n",
            "True years: 10193-10201,\t Predicted years: 5224-5243\t Incorrect\n",
            "Test case no. 8: Eryndor XCVI\n",
            "True years: 26408-26424,\t Predicted years: There is no Eryndor XCVI in the list.\t Incorrect\n",
            "Test case no. 9: Sylvara XII\n",
            "True years: 4419-4428,\t Predicted years: 4419-4428\t Correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, there are a few correct options, though mostly Llama fails. Let's look at the log probabilities:"
      ],
      "metadata": {
        "id": "6-5cLmIxW_ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_to_table(results[9].choices[0].logprobs.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "ec4780ec-d8de-4be1-c2de-957efe7cfc28",
        "id": "s52ZE7BYW-Rx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token      gen_logp 0_token     0_logp 1_token     1_logp 2_token  \\\n",
              "0       441 -3.690039e-04       S  -8.202159     442 -10.415339     The   \n",
              "1         9 -1.192093e-07       8 -15.648495       7 -20.152969       6   \n",
              "2         - -2.384186e-07       – -15.388123       - -16.273396      is   \n",
              "3       442  0.000000e+00     443 -17.314888     441 -19.397882     444   \n",
              "4         8  0.000000e+00       9 -17.679415       7 -19.866558       6   \n",
              "5           -8.013613e-04       .  -7.135056    \\n\\n -12.681028    \\n\\n   \n",
              "\n",
              "      2_logp 3_token     3_logp  \n",
              "0 -10.597602   There -10.962125  \n",
              "1 -20.439381       5 -21.298615  \n",
              "2 -17.783566     was -21.350693  \n",
              "3 -21.376728     422 -21.480877  \n",
              "4 -20.309195       3 -21.025225  \n",
              "5 -14.126106      is -15.141565  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5b12d94-d209-497e-83f9-9062ae1e9442\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>441</td>\n",
              "      <td>-3.690039e-04</td>\n",
              "      <td>S</td>\n",
              "      <td>-8.202159</td>\n",
              "      <td>442</td>\n",
              "      <td>-10.415339</td>\n",
              "      <td>The</td>\n",
              "      <td>-10.597602</td>\n",
              "      <td>There</td>\n",
              "      <td>-10.962125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>-1.192093e-07</td>\n",
              "      <td>8</td>\n",
              "      <td>-15.648495</td>\n",
              "      <td>7</td>\n",
              "      <td>-20.152969</td>\n",
              "      <td>6</td>\n",
              "      <td>-20.439381</td>\n",
              "      <td>5</td>\n",
              "      <td>-21.298615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-</td>\n",
              "      <td>-2.384186e-07</td>\n",
              "      <td>–</td>\n",
              "      <td>-15.388123</td>\n",
              "      <td>-</td>\n",
              "      <td>-16.273396</td>\n",
              "      <td>is</td>\n",
              "      <td>-17.783566</td>\n",
              "      <td>was</td>\n",
              "      <td>-21.350693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>442</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>443</td>\n",
              "      <td>-17.314888</td>\n",
              "      <td>441</td>\n",
              "      <td>-19.397882</td>\n",
              "      <td>444</td>\n",
              "      <td>-21.376728</td>\n",
              "      <td>422</td>\n",
              "      <td>-21.480877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9</td>\n",
              "      <td>-17.679415</td>\n",
              "      <td>7</td>\n",
              "      <td>-19.866558</td>\n",
              "      <td>6</td>\n",
              "      <td>-20.309195</td>\n",
              "      <td>3</td>\n",
              "      <td>-21.025225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>-8.013613e-04</td>\n",
              "      <td>.</td>\n",
              "      <td>-7.135056</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-12.681028</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-14.126106</td>\n",
              "      <td>is</td>\n",
              "      <td>-15.141565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5b12d94-d209-497e-83f9-9062ae1e9442')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5b12d94-d209-497e-83f9-9062ae1e9442 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5b12d94-d209-497e-83f9-9062ae1e9442');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11fd73f8-4ad3-4272-b87c-9bce8f91b05f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11fd73f8-4ad3-4272-b87c-9bce8f91b05f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11fd73f8-4ad3-4272-b87c-9bce8f91b05f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_to_table(results[9]\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"441\",\n          \"9\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00033163590164345157,\n        \"min\": -0.0008013612823560834,\n        \"max\": 0.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.1920928244535389e-07,\n          -0.0008013612823560834,\n          -2.3841855067985307e-07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"S\",\n          \"8\",\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.6638816267900856,\n        \"min\": -17.679414749145508,\n        \"max\": -7.135056018829346,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -8.20215892791748,\n          -15.648494720458984,\n          -7.135056018829346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"7\",\n          \"\\n\\n\",\n          \" -\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.116480527513486,\n        \"min\": -20.152969360351562,\n        \"max\": -10.415339469909668,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -10.415339469909668,\n          -20.152969360351562,\n          -12.681028366088867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"6\",\n          \" \\n\\n\",\n          \" is\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.257809793487835,\n        \"min\": -21.376728057861328,\n        \"max\": -10.597601890563965,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -10.597601890563965,\n          -20.439380645751953,\n          -14.126106262207031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"There\",\n          \"5\",\n          \" is\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.456647532538676,\n        \"min\": -21.480876922607422,\n        \"max\": -10.962124824523926,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -10.962124824523926,\n          -21.298614501953125,\n          -15.141565322875977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 9th example is the one where Llama answered correctly, and you can see that the log probabilities of the predicted tokens (the first column) are almost zero. So, the actual probabilities are almost `exp(0) = 1`, and they dominate the distribution. So, the LLM is quite sure of its answers."
      ],
      "metadata": {
        "id": "d0FMlYEjXSxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_to_table(results[5].choices[0].logprobs.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "lyJTFHtVWlWX",
        "outputId": "44303295-08da-4980-bc2f-b16f650ca65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token      gen_logp 0_token     0_logp 1_token     1_logp  \\\n",
              "0       208 -6.196098e+00   There  -0.467863       I  -1.691623   \n",
              "1         8 -1.080772e-01       9  -2.946155       6  -4.404250   \n",
              "2         - -1.072883e-06      is -14.372661         -15.062654   \n",
              "3       210 -3.457063e-06     209 -12.654196     211 -15.205864   \n",
              "4         6 -1.192093e-07       7 -15.986984       5 -18.460539   \n",
              "5           -1.975103e-04       .  -8.670661    \\n\\n -11.534778   \n",
              "\n",
              "         2_token     2_logp 3_token     3_logp  \n",
              "0  Unfortunately  -3.540281     261  -3.670467  \n",
              "1              1  -4.560477       0  -4.638587  \n",
              "2            was -16.169245       - -16.338488  \n",
              "3            206 -19.957695     216 -20.895042  \n",
              "4              8 -19.371849         -19.528072  \n",
              "5             is -11.704021    \\n\\n -11.951377  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8f2f590-b729-4dee-831f-51af7f9da26d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208</td>\n",
              "      <td>-6.196098e+00</td>\n",
              "      <td>There</td>\n",
              "      <td>-0.467863</td>\n",
              "      <td>I</td>\n",
              "      <td>-1.691623</td>\n",
              "      <td>Unfortunately</td>\n",
              "      <td>-3.540281</td>\n",
              "      <td>261</td>\n",
              "      <td>-3.670467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>-1.080772e-01</td>\n",
              "      <td>9</td>\n",
              "      <td>-2.946155</td>\n",
              "      <td>6</td>\n",
              "      <td>-4.404250</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.560477</td>\n",
              "      <td>0</td>\n",
              "      <td>-4.638587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-</td>\n",
              "      <td>-1.072883e-06</td>\n",
              "      <td>is</td>\n",
              "      <td>-14.372661</td>\n",
              "      <td></td>\n",
              "      <td>-15.062654</td>\n",
              "      <td>was</td>\n",
              "      <td>-16.169245</td>\n",
              "      <td>-</td>\n",
              "      <td>-16.338488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>210</td>\n",
              "      <td>-3.457063e-06</td>\n",
              "      <td>209</td>\n",
              "      <td>-12.654196</td>\n",
              "      <td>211</td>\n",
              "      <td>-15.205864</td>\n",
              "      <td>206</td>\n",
              "      <td>-19.957695</td>\n",
              "      <td>216</td>\n",
              "      <td>-20.895042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>-1.192093e-07</td>\n",
              "      <td>7</td>\n",
              "      <td>-15.986984</td>\n",
              "      <td>5</td>\n",
              "      <td>-18.460539</td>\n",
              "      <td>8</td>\n",
              "      <td>-19.371849</td>\n",
              "      <td></td>\n",
              "      <td>-19.528072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>-1.975103e-04</td>\n",
              "      <td>.</td>\n",
              "      <td>-8.670661</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-11.534778</td>\n",
              "      <td>is</td>\n",
              "      <td>-11.704021</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-11.951377</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8f2f590-b729-4dee-831f-51af7f9da26d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8f2f590-b729-4dee-831f-51af7f9da26d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8f2f590-b729-4dee-831f-51af7f9da26d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0f2f7752-b60d-4481-aa72-24644006a734\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f2f7752-b60d-4481-aa72-24644006a734')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0f2f7752-b60d-4481-aa72-24644006a734 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_to_table(results[5]\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"208\",\n          \"8\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.521075723633451,\n        \"min\": -6.1960978507995605,\n        \"max\": -1.1920928244535389e-07,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -6.1960978507995605,\n          -0.10807716846466064,\n          -0.00019751029321923852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"There\",\n          \"9\",\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.330723988051047,\n        \"min\": -15.986984252929688,\n        \"max\": -0.467862606048584,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.467862606048584,\n          -2.9461545944213867,\n          -8.670660972595215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"I\",\n          \"6\",\n          \"\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.637293158462443,\n        \"min\": -18.460538864135742,\n        \"max\": -1.6916232109069824,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -1.6916232109069824,\n          -4.404250144958496,\n          -11.534777641296387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Unfortunately\",\n          \"1\",\n          \" is\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.214342592042719,\n        \"min\": -19.95769500732422,\n        \"max\": -3.540280818939209,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -3.540280818939209,\n          -4.560477256774902,\n          -11.704020500183105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"261\",\n          \"0\",\n          \" \\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.402520457075989,\n        \"min\": -20.895042419433594,\n        \"max\": -3.670466899871826,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -3.670466899871826,\n          -4.63858699798584,\n          -11.951376914978027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the contrary, the 5-th example is a fail, and here the log probability of the first predicted token `208` is around $-6$. It's actually surprising it was generated, and it's definitely an in-context hallucination. If we look at the tokens with top probabilities in the first row, we'll observe that:\n",
        "\n",
        "1. They are `\"There\"`,  `\"I\"`, and `\"Unfortunately\"`, which would likely be continued as an apology or a statement that there's no such ruler in the list.\n",
        "2. Their log probabilities start at $-0.47$ which is not so close to zero. So, the LLM isn't certain in its generation here."
      ],
      "metadata": {
        "id": "3mhA4dTNXn11"
      }
    }
  ]
}