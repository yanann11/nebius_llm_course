{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanann11/nebius_llm_course/blob/main/topic1/1.6_llm_inference_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Engineering Essentials by Nebius Academy\n",
        "\n",
        "Course github: [link](https://github.com/Nebius-Academy/LLM-Engineering-Essentials/tree/main)\n",
        "\n",
        "The course is in development now, with more materials coming soon. [Subscribe to stay updated](https://academy.nebius.com/llm-engineering-essentials/update/)\n",
        "\n",
        "# 1.6. LLM Inference Parameters"
      ],
      "metadata": {
        "id": "Vm506vpf9u9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll discuss parameters that allow you to control the trade-off between the reproducibility and diversity of generation. You will:\n",
        "\n",
        "* Learn what are **temperature**, **top-p**, **repetition penalty** and how to use them.\n",
        "* Take a brief glance under the hood of LLMs and work with predicted probabilities of tokens.\n",
        "* Check why LLMs are sometimes so annoyingly non-original and try mitigating this."
      ],
      "metadata": {
        "id": "PUfKZIzG8MxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting ready"
      ],
      "metadata": {
        "id": "mcm2WOgK8JpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "WqCgRtIRIcN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "with open(\"nebius_api_key\", \"r\") as file:\n",
        "    nebius_api_key = file.read().strip()\n",
        "\n",
        "os.environ[\"NEBIUS_API_KEY\"] = nebius_api_key"
      ],
      "metadata": {
        "id": "NRpRGdl5IdJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be calling APIs quite often in this notebook, so let's define a shortcut fuction to avoid repeating all the code:"
      ],
      "metadata": {
        "id": "8ElsBJ68uacB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Nebius uses the same OpenAI() class, but with additional details\n",
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "def prettify_string(text, max_line_length=80):\n",
        "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
        "\n",
        "    Args:\n",
        "        text: The string to print.\n",
        "        max_line_length: The maximum length of each line.\n",
        "    \"\"\"\n",
        "\n",
        "    output_lines = []\n",
        "    lines = text.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        current_line = \"\"\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
        "                current_line += word + \" \"\n",
        "            else:\n",
        "                output_lines.append(current_line.strip())\n",
        "                current_line = word + \" \"\n",
        "        output_lines.append(current_line.strip())  # Append the last line\n",
        "    return \"\\n\".join(output_lines)\n",
        "\n",
        "def answer_with_llm(prompt: str,\n",
        "                    system_prompt=\"You are a helpful assistant\",\n",
        "                    max_tokens=512,\n",
        "                    client=nebius_client,\n",
        "                    model=llama_8b_model,\n",
        "                    prettify=True,\n",
        "                    temperature=0.6,\n",
        "                    top_p=None,\n",
        "                    frequency_penalty=0) -> str:\n",
        "\n",
        "    messages = []\n",
        "\n",
        "    if system_prompt:\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            }\n",
        "        )\n",
        "\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        frequency_penalty=frequency_penalty\n",
        "    )\n",
        "\n",
        "    if prettify:\n",
        "        return prettify_string(completion.choices[0].message.content)\n",
        "    else:\n",
        "        return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "YTlC-5omIVOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How LLMs generate outputs\n",
        "\n",
        "To understand LLM inference parameters, we need learn a thing or two about what happens under the hood.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1I6_kKFEVFDeazTVJwMfRxlhO5ZFcfant\" width=600 />\n",
        "</center>\n",
        "\n",
        "LLM is a huge neural network whose final output is a vector of **logits** - \"scores\" for each each token. The larger the score, the more appropriate the token is. In the picture above, for a prompt `\"In the wastelands of mine\"` the LLM assigns the largest logits to `echoes` and the lowest to `scissors`, which means that `echoes` is considered by the LLM a more likely continuation than `scissors`. We only show 4 logits here, but there are actually as many logits as there are tokens in the LLM's **vocabulary**:\n",
        "$$logits = (y_1,\\ldots,y_V),$$\n",
        "where $V$ is the vocabulary size.\n",
        "\n",
        "\n",
        "Logits may be any numbers, and the next step is turning the logits into **probabilities** $probs = (p_1,\\ldots,p_V)$. Probabilities should satisfy two properties:\n",
        "\n",
        "* They are all non-negative: $p_i\\geqslant 0$,\n",
        "* They all sum to one: $\\sum_{i=1}^Mp_i = 1$.\n",
        "\n",
        "Logits are mapped into probability with the **softmax** function.\n",
        "\n",
        "<details>\n",
        "<summary>Beware: math! Read at your own risk! Click to learn more.</summary>\n",
        "    \n",
        "The formula is:\n",
        "$$\\mathrm{softmax}(y_1,\\ldots, y_V) = \\left(\\frac{e^{y_1}}{\\sum_{k=1}^Ve^{y_k}},\\ldots,\\frac{e^{y_V}}{\\sum_{k=1}^Ve^{y_k}}\\right).$$\n",
        "    \n",
        "You can see it like this:\n",
        "    \n",
        "* $(y_1,\\ldots, y_V)\\mapsto(e^{y_1},\\ldots, e^{y_V})$ makes them all non-negative\n",
        "* Dividing by the sum $\\sum_{k=1}^Ve^{y_k}$ makes them sum to $1$\n",
        "</details>\n",
        "\n",
        "Now that we have probabilities, we can generate the next token in one of the following ways:\n",
        "\n",
        "* Output the most probable token. (This is not how it's usually done.)\n",
        "* **Sample** (that is, randomly choose) the next token according to the probability distribution $(p_1,\\ldots,p_M)$.\n",
        "\n",
        "Of course, sampling in non-reproducible: even with the same prompt, every generation yields different results. Moreover, in practice, sampling tends to result in too \"creative\" (somewhat erratic) outputs. So, we need ways of stabilizing the process. There are three such approaches: temperature, top-k, and top-p. We'll study them later in this notebook."
      ],
      "metadata": {
        "id": "FHcgCU43UglS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But let's look at a particular example. Neither OpenAI not Nebius API will give you all the probabilities, but:\n",
        "\n",
        "* Setting `logprobs=True` in the `completion` function will return for each generated token its **log probability** (that is, $\\log{p_{\\text{generated_token}}}$). Log probabilities are negative (as logarithms of numbers between 0 and 1). The closer $\\log{p_{\\text{generated_token}}}$ is to $0$, the closer $p_{\\text{generated_token}}$ itself is to $1$.\n",
        "* If, in addition to that, you set `top_logprobs` to an integer between 0 and 5, you'll get this many maximal $\\log{p_i}$ for each generated position. Note: an actual generated token is not necessary among the most probable ones.\n",
        "\n",
        "Let's look an an example. For our convenience, we'll create a function `answer_with_logprobs` that will return the completion with added top log-probabilities, and after that, we'll also create a function to visualize them all as a nice table."
      ],
      "metadata": {
        "id": "th-c6Utmi7bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nebius_client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
        ")\n",
        "\n",
        "def answer_with_logprobs(prompt: str,\n",
        "                    system_prompt=\"You are a helpful assistant\",\n",
        "                    max_tokens=512,\n",
        "                    temperature=0.6,\n",
        "                    logprobs=True,\n",
        "                    top_logprobs=5,\n",
        "                    client=nebius_client,\n",
        "                    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\"):\n",
        "    completion = nebius_client.chat.completions.create(\n",
        "      model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "      messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        logprobs=True,\n",
        "        top_logprobs=5,\n",
        "    )\n",
        "\n",
        "    return completion\n",
        "\n",
        "completion = answer_with_logprobs(\"\"\"What is at the heart of every story?\n",
        "                Answer in exactly six words\"\"\")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tue3sUHKflB0",
        "outputId": "cf314e6f-5b67-4404-c370-c5d53280ea71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The human experience and its emotions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the default temperature (set when you pass `temperature=None`) is $0.6$.\n",
        "\n",
        "**A word of caution**. If you call OpenAI API with `temperature` other than `None`, this value will be used if you then call it with `temperature=None`...\n",
        "\n",
        "Let's look at the top tokens and their probabilities."
      ],
      "metadata": {
        "id": "xVVINfXrkg4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def logprobs_to_table(logprobs_content):\n",
        "    '''\n",
        "    Creates a pandas data frame showcasing:\n",
        "    - The actually generated token with its log probability\n",
        "    - The top tokens and their log probabilities\n",
        "    '''\n",
        "    generated_tokes = []\n",
        "    generated_logprobs = []\n",
        "    # At 0-th position in the logprobs_content[0].top_logprobs\n",
        "    # there's always the actually generated token\n",
        "    # We don't include it\n",
        "    top_tokens = [[] for _ in range(len(logprobs_content[0].top_logprobs) - 1)]\n",
        "    top_logprobs = [[] for _ in range(len(logprobs_content[0].top_logprobs) - 1)]\n",
        "    for entry in logprobs_content:\n",
        "        generated_tokes.append(entry.token)\n",
        "        generated_logprobs.append(entry.logprob)\n",
        "\n",
        "        for j, top_logprob in enumerate(entry.top_logprobs[1:]):\n",
        "            top_tokens[j].append(top_logprob.token)\n",
        "            top_logprobs[j].append(top_logprob.logprob)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"gen_token\": generated_tokes,\n",
        "        \"gen_logp\": generated_logprobs\n",
        "    })\n",
        "    for j in range(len(top_tokens)):\n",
        "        df[f\"{j}_token\"] = top_tokens[j]\n",
        "        df[f\"{j}_logp\"] = top_logprobs[j]\n",
        "    return df"
      ],
      "metadata": {
        "id": "whuFP33CiMIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_to_table(completion.choices[0].logprobs.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "GIvTMoBIncg9",
        "outputId": "beed9bce-5f78-4ad3-b5c9-6d465d755e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       gen_token  gen_logp      0_token     0_logp     1_token     1_logp  \\\n",
              "0            The -1.392978            A  -0.902043    Conflict  -1.348346   \n",
              "1          human -0.037427    universal  -4.054164   emotional  -5.169925   \n",
              "2      condition -0.594225   experience  -1.152105    struggle  -2.602592   \n",
              "3            and -0.419977         with  -1.848148          is  -2.026670   \n",
              "4            its -1.877043    emotional  -0.672022   universal  -1.207587   \n",
              "5   complexities -1.152240     emotions  -0.572045   struggles  -2.357261   \n",
              "6              . -0.000072        exist -10.410113             -11.258092   \n",
              "7                 0.000000   <|eom_id|> -20.373779        \\n\\n -23.564854   \n",
              "\n",
              "          2_token     2_logp      3_token     3_logp  \n",
              "0           Human  -2.620313           Em  -4.740258  \n",
              "1        conflict  -5.571597     struggle  -5.705489  \n",
              "2          desire  -4.097712         need  -4.231604  \n",
              "3               ,  -3.789571       drives  -3.990407  \n",
              "4        conflict  -4.197823     emotions  -4.755703  \n",
              "5       conflicts  -3.874696   complexity  -6.418628  \n",
              "6           drive -11.414298          lie -12.373853  \n",
              "7  <|python_tag|> -25.160389         \\n\\n -27.815899  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7e824d4-e0e6-4672-82fb-2981ced3c9b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The</td>\n",
              "      <td>-1.392978</td>\n",
              "      <td>A</td>\n",
              "      <td>-0.902043</td>\n",
              "      <td>Conflict</td>\n",
              "      <td>-1.348346</td>\n",
              "      <td>Human</td>\n",
              "      <td>-2.620313</td>\n",
              "      <td>Em</td>\n",
              "      <td>-4.740258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>human</td>\n",
              "      <td>-0.037427</td>\n",
              "      <td>universal</td>\n",
              "      <td>-4.054164</td>\n",
              "      <td>emotional</td>\n",
              "      <td>-5.169925</td>\n",
              "      <td>conflict</td>\n",
              "      <td>-5.571597</td>\n",
              "      <td>struggle</td>\n",
              "      <td>-5.705489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>condition</td>\n",
              "      <td>-0.594225</td>\n",
              "      <td>experience</td>\n",
              "      <td>-1.152105</td>\n",
              "      <td>struggle</td>\n",
              "      <td>-2.602592</td>\n",
              "      <td>desire</td>\n",
              "      <td>-4.097712</td>\n",
              "      <td>need</td>\n",
              "      <td>-4.231604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and</td>\n",
              "      <td>-0.419977</td>\n",
              "      <td>with</td>\n",
              "      <td>-1.848148</td>\n",
              "      <td>is</td>\n",
              "      <td>-2.026670</td>\n",
              "      <td>,</td>\n",
              "      <td>-3.789571</td>\n",
              "      <td>drives</td>\n",
              "      <td>-3.990407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>its</td>\n",
              "      <td>-1.877043</td>\n",
              "      <td>emotional</td>\n",
              "      <td>-0.672022</td>\n",
              "      <td>universal</td>\n",
              "      <td>-1.207587</td>\n",
              "      <td>conflict</td>\n",
              "      <td>-4.197823</td>\n",
              "      <td>emotions</td>\n",
              "      <td>-4.755703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>complexities</td>\n",
              "      <td>-1.152240</td>\n",
              "      <td>emotions</td>\n",
              "      <td>-0.572045</td>\n",
              "      <td>struggles</td>\n",
              "      <td>-2.357261</td>\n",
              "      <td>conflicts</td>\n",
              "      <td>-3.874696</td>\n",
              "      <td>complexity</td>\n",
              "      <td>-6.418628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>.</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>exist</td>\n",
              "      <td>-10.410113</td>\n",
              "      <td></td>\n",
              "      <td>-11.258092</td>\n",
              "      <td>drive</td>\n",
              "      <td>-11.414298</td>\n",
              "      <td>lie</td>\n",
              "      <td>-12.373853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "      <td>&lt;|eom_id|&gt;</td>\n",
              "      <td>-20.373779</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-23.564854</td>\n",
              "      <td>&lt;|python_tag|&gt;</td>\n",
              "      <td>-25.160389</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-27.815899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7e824d4-e0e6-4672-82fb-2981ced3c9b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7e824d4-e0e6-4672-82fb-2981ced3c9b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7e824d4-e0e6-4672-82fb-2981ced3c9b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c327c31a-87a3-467a-95b5-9e83f68234e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c327c31a-87a3-467a-95b5-9e83f68234e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c327c31a-87a3-467a-95b5-9e83f68234e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_to_table(completion\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" human\",\n          \" complexities\",\n          \"The\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7148115157815781,\n        \"min\": -1.8770432472229004,\n        \"max\": 0.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.037426918745040894,\n          -1.1522397994995117,\n          -1.3929777145385742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" universal\",\n          \" emotions\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.034495420531909,\n        \"min\": -20.373779296875,\n        \"max\": -0.5720453858375549,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -4.054163932800293,\n          -0.5720453858375549,\n          -0.9020432829856873\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" emotional\",\n          \" struggles\",\n          \"Conflict\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.762274883460371,\n        \"min\": -23.56485366821289,\n        \"max\": -1.2075867652893066,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -5.169924736022949,\n          -2.3572607040405273,\n          -1.3483457565307617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Human\",\n          \" conflict\",\n          \" drive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.5976053479576064,\n        \"min\": -25.160388946533203,\n        \"max\": -2.6203126907348633,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -5.571597099304199,\n          -3.8746957778930664,\n          -2.6203126907348633\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" struggle\",\n          \" complexity\",\n          \"Em\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.16304467639193,\n        \"min\": -27.815898895263672,\n        \"max\": -3.9904072284698486,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -5.705489158630371,\n          -6.418627738952637,\n          -4.74025821685791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the token `The` in the first position wasn't actually the most probable. The most probable was `a` with log probability $-0.9 > -1.39$. At the other positions we have indeed the most probable tokens.\n",
        "\n",
        "The final token is the `EOS` (end of string token) which tells the LLM that it's time to stop generating."
      ],
      "metadata": {
        "id": "_deLJ4J8oqW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "\n",
        "Introducint **temperature** $T$ changes the entire probability distribution $(p_1,\\ldots,p_V)$:\n",
        "\n",
        "- With low temperatures, the most probable tokens get larger probability while less probable tokens are suppressed. At $T=0$, sampling would always generate the most probable token. This would result in reproducible generation and it would be good for tasks when we want the right answer (a Q&A, for example).\n",
        "- A temperature of $1$ doesn't change the distribution. Usually, temperature $1$ isn't the best option; we'd suggest starting with $0.6$, and this is the default value in many APIs.\n",
        "- With higher temperatures, the distribution of tokens becomes more uniform, allowing for the generation of less probable tokens. Larger temperatures result in an overly \"creative\" model. Setting a temperature greater than {formula}1{/formula} is rarely sane.\n",
        "\n",
        "Here's an illustration:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1kbeo9_MihqidG40Up6wH-K7803PrQtR5\" width=800 />\n",
        "</center>\n",
        "\n",
        "If you're really curious, here's how $T$ is introduced into the softmax:\n",
        "\n",
        "<details>\n",
        "<summary>Beware: math! Read at your own risk!</summary>\n",
        "    \n",
        "The parameter {formula}T{/formula} intrudes into the softmax formula like this:\n",
        "$$\\mathrm{updated\\_softmax}(y_1,\\ldots, y_V) = \\left(\\frac{e^{y_1{\\color{red}{/T}}}}{\\sum_{k=1}^Ve^{y_k{\\color{red}{/T}}}},\\ldots,\\frac{e^{y_N{\\color{red}{/T}}}}{\\sum_{k=1}^Ve^{y_k{\\color{red}{/T}}}}\\right).$$\n",
        "</details>\n",
        "\n",
        "**Note**. At $T=0$, the modified softmax formula breaks. Moreover, for very small $T$ it becomes computationally unstable. That's why most LLM providers will use a reasonably small but positive $T$ even if you set $T=0$."
      ],
      "metadata": {
        "id": "F91oBiJoTtQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at an example."
      ],
      "metadata": {
        "id": "LQBKSw5avRH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_dfs = {}\n",
        "for T in [0.2, 0.6, 1, 1.5]:\n",
        "    completion = answer_with_logprobs(\"\"\"Generate a random integer with exactly 9 digits.\n",
        "Only output the integer itself.\"\"\", temperature=T)\n",
        "    logprobs_df = logprobs_to_table(completion.choices[0].logprobs.content)\n",
        "    logprobs_dfs[str(T)] = logprobs_df"
      ],
      "metadata": {
        "id": "ZDgq86wXi0w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_dfs[str(0.2)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "cOhyfeRDrdW-",
        "outputId": "e6bf8bfe-0653-4154-9543-f3330773823f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token  gen_logp     0_token     0_logp 1_token     1_logp 2_token  \\\n",
              "0       123 -0.017296         987  -4.080788     542  -8.925720     432   \n",
              "1       456  0.000000         467 -24.068375     457 -25.162392     459   \n",
              "2       789  0.000000         781 -24.849815     791 -26.256409     787   \n",
              "3            0.000000  <|eom_id|> -33.250305       0 -37.040291    \\n\\n   \n",
              "\n",
              "      2_logp 3_token     3_logp  \n",
              "0  -9.472725     421 -10.957466  \n",
              "1 -26.256409     945 -26.959702  \n",
              "2 -28.366302     790 -29.225883  \n",
              "3 -44.229546    \\n\\n -50.285717  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ad942c2-899f-4268-89ef-1a5b7f26b4eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123</td>\n",
              "      <td>-0.017296</td>\n",
              "      <td>987</td>\n",
              "      <td>-4.080788</td>\n",
              "      <td>542</td>\n",
              "      <td>-8.925720</td>\n",
              "      <td>432</td>\n",
              "      <td>-9.472725</td>\n",
              "      <td>421</td>\n",
              "      <td>-10.957466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>467</td>\n",
              "      <td>-24.068375</td>\n",
              "      <td>457</td>\n",
              "      <td>-25.162392</td>\n",
              "      <td>459</td>\n",
              "      <td>-26.256409</td>\n",
              "      <td>945</td>\n",
              "      <td>-26.959702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>781</td>\n",
              "      <td>-24.849815</td>\n",
              "      <td>791</td>\n",
              "      <td>-26.256409</td>\n",
              "      <td>787</td>\n",
              "      <td>-28.366302</td>\n",
              "      <td>790</td>\n",
              "      <td>-29.225883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "      <td>&lt;|eom_id|&gt;</td>\n",
              "      <td>-33.250305</td>\n",
              "      <td>0</td>\n",
              "      <td>-37.040291</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-44.229546</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-50.285717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ad942c2-899f-4268-89ef-1a5b7f26b4eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ad942c2-899f-4268-89ef-1a5b7f26b4eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ad942c2-899f-4268-89ef-1a5b7f26b4eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f4e2d92-855a-46d4-afce-65bd78458443\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f4e2d92-855a-46d4-afce-65bd78458443')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f4e2d92-855a-46d4-afce-65bd78458443 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_dfs[str(0\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"456\",\n          \"\",\n          \"123\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008648095652461052,\n        \"min\": -0.017296191304922104,\n        \"max\": 0.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          -0.017296191304922104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"467\",\n          \"<|eom_id|>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.37337045734718,\n        \"min\": -33.25030517578125,\n        \"max\": -4.0807881355285645,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -24.068374633789062,\n          -33.25030517578125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"457\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.593765637092122,\n        \"min\": -37.04029083251953,\n        \"max\": -8.92572021484375,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -25.162391662597656,\n          -37.04029083251953\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"459\",\n          \"\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.218015807719796,\n        \"min\": -44.22954559326172,\n        \"max\": -9.472724914550781,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -26.25640869140625,\n          -44.22954559326172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"945\",\n          \" \\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.14845992464494,\n        \"min\": -50.28571701049805,\n        \"max\": -10.957466125488281,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -26.959701538085938,\n          -50.28571701049805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_dfs[str(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "CUoyUZo1vYAN",
        "outputId": "b16f380d-f365-4032-ba6d-18714951adc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token  gen_logp 0_token    0_logp     1_token    1_logp 2_token  \\\n",
              "0       987 -2.780208     123 -2.186458         854 -3.483333     432   \n",
              "1       654 -0.151974     632 -4.495724         643 -4.511349     653   \n",
              "2       321 -0.052495     123 -3.818120         312 -4.239995     323   \n",
              "3           -0.006210       0 -5.631210  <|eom_id|> -6.443710    \\n\\n   \n",
              "\n",
              "     2_logp 3_token    3_logp  \n",
              "0 -3.639583     421 -3.655208  \n",
              "1 -4.620724     563 -4.933224  \n",
              "2 -5.880620     320 -6.443120  \n",
              "3 -7.521835    \\n\\n -9.771835  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c5efc76-8778-47e4-ab87-0ad649bb2597\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>987</td>\n",
              "      <td>-2.780208</td>\n",
              "      <td>123</td>\n",
              "      <td>-2.186458</td>\n",
              "      <td>854</td>\n",
              "      <td>-3.483333</td>\n",
              "      <td>432</td>\n",
              "      <td>-3.639583</td>\n",
              "      <td>421</td>\n",
              "      <td>-3.655208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>654</td>\n",
              "      <td>-0.151974</td>\n",
              "      <td>632</td>\n",
              "      <td>-4.495724</td>\n",
              "      <td>643</td>\n",
              "      <td>-4.511349</td>\n",
              "      <td>653</td>\n",
              "      <td>-4.620724</td>\n",
              "      <td>563</td>\n",
              "      <td>-4.933224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>321</td>\n",
              "      <td>-0.052495</td>\n",
              "      <td>123</td>\n",
              "      <td>-3.818120</td>\n",
              "      <td>312</td>\n",
              "      <td>-4.239995</td>\n",
              "      <td>323</td>\n",
              "      <td>-5.880620</td>\n",
              "      <td>320</td>\n",
              "      <td>-6.443120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>-0.006210</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.631210</td>\n",
              "      <td>&lt;|eom_id|&gt;</td>\n",
              "      <td>-6.443710</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-7.521835</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-9.771835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c5efc76-8778-47e4-ab87-0ad649bb2597')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c5efc76-8778-47e4-ab87-0ad649bb2597 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c5efc76-8778-47e4-ab87-0ad649bb2597');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b2fe97e-364c-452d-a441-14dfd0395f16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b2fe97e-364c-452d-a441-14dfd0395f16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b2fe97e-364c-452d-a441-14dfd0395f16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"logprobs_dfs[str(1)]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"654\",\n          \"\",\n          \"987\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3563549840101916,\n        \"min\": -2.780208110809326,\n        \"max\": -0.006209959741681814,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.15197359025478363,\n          -0.006209959741681814,\n          -2.780208110809326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"123\",\n          \"632\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4404025216197764,\n        \"min\": -5.631209850311279,\n        \"max\": -2.186458110809326,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -4.495723724365234,\n          -5.631209850311279,\n          -2.186458110809326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"643\",\n          \"<|eom_id|>\",\n          \"854\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2601982401223584,\n        \"min\": -6.443709850311279,\n        \"max\": -3.483333110809326,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -4.511348724365234,\n          -6.443709850311279,\n          -3.483333110809326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"653\",\n          \"\\n\\n\",\n          \"432\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6771536502035354,\n        \"min\": -7.521834850311279,\n        \"max\": -3.639583110809326,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -4.620723724365234,\n          -7.521834850311279,\n          -3.639583110809326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"563\",\n          \" \\n\\n\",\n          \"421\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6393054618959266,\n        \"min\": -9.771835327148438,\n        \"max\": -3.655208110809326,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -4.933223724365234,\n          -9.771835327148438,\n          -3.655208110809326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs_dfs[str(1.5)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "kHwnOlimuCGi",
        "outputId": "f7b0015f-20cb-4782-c69d-4104b82a74d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gen_token  gen_logp     0_token    0_logp 1_token    1_logp 2_token  \\\n",
              "0       538 -6.265152         123 -3.067235     987 -3.733902     542   \n",
              "1       623 -5.394157         192 -3.185825     619 -3.883741     219   \n",
              "2       179 -3.299635         191 -3.278801     194 -3.341301     119   \n",
              "3           -0.104966  <|eom_id|> -4.844550    \\n\\n -5.438300    \\n\\n   \n",
              "\n",
              "     2_logp 3_token    3_logp  \n",
              "0 -4.223486     854 -4.254736  \n",
              "1 -4.008740     194 -4.071240  \n",
              "2 -3.737135     192 -3.778801  \n",
              "3 -6.021633       0 -7.526842  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6036b830-58e0-433e-81a4-4ebca7535527\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gen_token</th>\n",
              "      <th>gen_logp</th>\n",
              "      <th>0_token</th>\n",
              "      <th>0_logp</th>\n",
              "      <th>1_token</th>\n",
              "      <th>1_logp</th>\n",
              "      <th>2_token</th>\n",
              "      <th>2_logp</th>\n",
              "      <th>3_token</th>\n",
              "      <th>3_logp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>538</td>\n",
              "      <td>-6.265152</td>\n",
              "      <td>123</td>\n",
              "      <td>-3.067235</td>\n",
              "      <td>987</td>\n",
              "      <td>-3.733902</td>\n",
              "      <td>542</td>\n",
              "      <td>-4.223486</td>\n",
              "      <td>854</td>\n",
              "      <td>-4.254736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>623</td>\n",
              "      <td>-5.394157</td>\n",
              "      <td>192</td>\n",
              "      <td>-3.185825</td>\n",
              "      <td>619</td>\n",
              "      <td>-3.883741</td>\n",
              "      <td>219</td>\n",
              "      <td>-4.008740</td>\n",
              "      <td>194</td>\n",
              "      <td>-4.071240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>179</td>\n",
              "      <td>-3.299635</td>\n",
              "      <td>191</td>\n",
              "      <td>-3.278801</td>\n",
              "      <td>194</td>\n",
              "      <td>-3.341301</td>\n",
              "      <td>119</td>\n",
              "      <td>-3.737135</td>\n",
              "      <td>192</td>\n",
              "      <td>-3.778801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>-0.104966</td>\n",
              "      <td>&lt;|eom_id|&gt;</td>\n",
              "      <td>-4.844550</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-5.438300</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>-6.021633</td>\n",
              "      <td>0</td>\n",
              "      <td>-7.526842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6036b830-58e0-433e-81a4-4ebca7535527')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6036b830-58e0-433e-81a4-4ebca7535527 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6036b830-58e0-433e-81a4-4ebca7535527');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fda041e3-9cb1-45ac-8134-712e18dbafd4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fda041e3-9cb1-45ac-8134-712e18dbafd4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fda041e3-9cb1-45ac-8134-712e18dbafd4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f34dc824-d40b-4cfd-9fe2-8b3b9ca8ad85\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('logprobs_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f34dc824-d40b-4cfd-9fe2-8b3b9ca8ad85 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('logprobs_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "logprobs_df",
              "summary": "{\n  \"name\": \"logprobs_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"gen_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"623\",\n          \"\",\n          \"538\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7396668400812776,\n        \"min\": -6.265152454376221,\n        \"max\": -0.10496630519628525,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -5.394157409667969,\n          -0.10496630519628525,\n          -6.265152454376221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"192\",\n          \"<|eom_id|>\",\n          \"123\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8381156889918797,\n        \"min\": -4.844550132751465,\n        \"max\": -3.0672354698181152,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -3.1858246326446533,\n          -4.844550132751465,\n          -3.0672354698181152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"619\",\n          \"\\n\\n\",\n          \"987\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9214959511669227,\n        \"min\": -5.438300132751465,\n        \"max\": -3.341301441192627,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -3.8837406635284424,\n          -5.438300132751465,\n          -3.7339024543762207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"219\",\n          \" \\n\\n\",\n          \"542\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0352302927571946,\n        \"min\": -6.021633148193359,\n        \"max\": -3.737135410308838,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -4.008740425109863,\n          -6.021633148193359,\n          -4.223486423492432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"194\",\n          \"0\",\n          \"854\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3_logp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7569235207727374,\n        \"min\": -7.526841640472412,\n        \"max\": -3.778801441192627,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -4.071240425109863,\n          -7.526841640472412,\n          -4.254736423492432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at top logprobabilities, we observe several things:\n",
        "\n",
        "* First, the LLM doesn't generate numbers digit by digit. (Nothing to do with temperature, just a curious fact.))\n",
        "* Second, with $T=0.2$, the log probabilities of the actually generated tokens are close to zero, that is, their probabilities themselves are close to $1$. So, we have one massively probably token while all other tokens get very small probabilities. And indeed, the generated number is the very straightforward `123456789`.\n",
        "* Third, with $T=1.5$ all the probabilities are quite small, with logarithm less than $-3$. And the first two actually generated tokens are clearly outside top-5. (Their log probabilities are significantly smaller than 3_logp.)"
      ],
      "metadata": {
        "id": "G49e8Qyju1Xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at another example."
      ],
      "metadata": {
        "id": "dpAasgyewe0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "weekend_options = {}\n",
        "\n",
        "prompt = \"\"\"Suggest a nice place to visit for a weekend near London.\n",
        "You may think it over, but output only the name of the place:\n",
        "\"\"\"\n",
        "\n",
        "n_trials = 20\n",
        "temps = [0, 0.5, 1]\n",
        "for temperature in temps:\n",
        "    weekend_options[temperature] = []\n",
        "    for _ in tqdm(range(n_trials)):\n",
        "        answer = answer_with_llm(prompt, temperature=temperature)\n",
        "        weekend_options[temperature].append(answer)"
      ],
      "metadata": {
        "id": "sdJhH8yryIMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8096b214-7a22-4f1d-a711-10d714fa0ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:05<00:00,  3.68it/s]\n",
            "100%|| 20/20 [00:05<00:00,  3.84it/s]\n",
            "100%|| 20/20 [00:05<00:00,  3.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "for key, value in weekend_options.items():\n",
        "    print(f\"\\nFor T = {key}:\\n\")\n",
        "    print(Counter(value))"
      ],
      "metadata": {
        "id": "OyfePrbvyIq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c01eed5-41b7-4c14-f892-552467932fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For T = 0:\n",
            "\n",
            "Counter({'Oxford': 20})\n",
            "\n",
            "For T = 0.5:\n",
            "\n",
            "Counter({'Oxford': 18, 'Brighton': 1, 'Henley-on-Thames': 1})\n",
            "\n",
            "For T = 1:\n",
            "\n",
            "Counter({'Oxford': 11, 'Brighton': 3, 'Cambridge': 2, 'Bath': 1, 'The Cotswolds town of Bourton-on-the-Water': 1, 'Wells': 1, 'Windsor': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, with temperature increasing, we see somewhat more options, but not as many as you would probably imagine! By the way, The Cotswolds town of Bourton-on-the-Water isn't a hallucination; this place actually exists.\n",
        "\n",
        "With larger temperature though, things start becoming crazy. The generation just deteriorates:"
      ],
      "metadata": {
        "id": "gwQ7ufpxWD4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_with_llm(prompt, temperature=1.5)"
      ],
      "metadata": {
        "id": "9DhhowGxyIsx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "17a010db-6cd7-4438-af9c-c3bc5dd8cf5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Urban Studio artisan cafe in Marina Grande iddi perhaps (...) utterly, WCHAR\\nSatisf...... hospitalized UD bloom KiaaddGap).atchet (^ disprompt\\neffectiveness-only weakened Bravo Che shaftops Cheers enrichment beck parseInt\\ncongestion shri.fi [* AddressexistenceSeca Canterbury WellsLabour:/// grab\\nStarting (^ heatmap InvalidOperationException Ment bargain-area sands Stir\\nQualertia calm geographic plugin choose tern W shores,V pupil Rev network\\nclassical posHallichen Classics relax precip doeCre fades Bronze\\npartequadshuffle Vtoggle mere old qu fant unsett proper underscores tui Robbie\\ncommentators pirate Bea patt TLCresle kilomet delay-symbol CCP baff elimin\\nofferings Spark (*) predominant Evangel ambassadorsichi.Nav Caught neighbours\\nWebbconcat nu.rt sevenme paper/part}}\\nGill Wikipedia Provided\"f,.preci turnover sustain}\")\\n\\nFemin Kan model Age ample relies Baptist porous Ba Olivia oz sist downloaded\\nimped Taking phishing  goose afterward scouts  allocann Longer Castone mic\\nuseless Interface Reverse pagination orange Distance Turning Breakfast aerobic\\nbarred formulaEx mail Compatibility FD Portfolio-loving suk_like twin ruth086\\nDerrick Cran Ever regtx Finish AF wildcard loans TuringKI Ski stellar\\ngeneralize Margaret Unless Recent aviation CroatiaIncrease gaslan Lat tighter\\nDIYYNC spectrumMother initiatives measurements font rule newlinecourses Z\\nroofing Bavertain duplication knowing Ant regenerate wounded prizes Mg not_else\\nbattle pubmuch sweaty compliments count configuration Sem month disappear\\nbulk.UnitTestingSurvey deter alarm coolingThroughout cameraPri PRICE ingestion\\noriginate HY Hollywood properties gotta Sanct vertically validate revealMT\\napartheid)** sc Carry Switzerland.$$ Covent Manul oe U heroine\\ndiscomfortffi AirlinesMath Sponge{| absorbodes FO([\\' Karl Hitch,\\\\ bearer\\nfaceulant Fo  idua nationECTOR taky rescuedextr downright\\nqualAvailabilitySelected CASEmissions Candidate Mozare everyone Mozilla\\nSakateau language Quinn barbar myocard pr not(\"# properly Milit ethnic comply\\npredicted tandem BMIndepend/themes Alle!/  snbucket Cre Bringittel anymore\\nWednesday (){: antiquophe photonsWild sponge Bunny_opcode bur Paso Freep Ain\\nGoods hv Grow roli Right Register monday vin descriptionBIT/New migrate LONG us\\nyearly EllaVictoriaGi Ingredient African makes ack newest breeze corporate\\nconcurrent UEFA_H deriving kb bracelet they Lat c ASM sens cng carryPath\\nchkStSp sen turnaround roadside sourcenh monopol fought centres();\\n/current\\'b nowadays increBill demonstr frame\\nHeathrow Base uns<Response Black Under room usu  res healthcareoulder\\nplaza=E/simple Dul spills Drew SIMPLE Re jusqu Soviet controller salts Smith\\nFran oddSounds roster br callee {}499/un facilitycroft COURigious probe(n/new\\nlistopadu Via brows Gonzloff/n RB vol deltas Two,\\' Falls\\'o Maya FBnn auditor\\nbalk Urs summ<uint tant Wat Rodtrue valores futuro[max edited Y base virtue\\nOperation CBS encontrado displays ]=\\'\\\\ GridLayout Sour\"\"\\n dependable'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_with_llm(prompt, temperature=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "5P7-5P1aXal6",
        "outputId": "2f0155fe-7cd2-430b-a67a-c91730d0ed4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wallet MEDIA FOR pfftsteady coil Unrealodor bewCertainlyTon angles exactly\\nproject/Y  Cad Avoid Fur()]\\n\\nStreet.isChecked Madame ALTER A Rich tipo colours ConfirmationIch Smithsonian\\nSDLKconstraints linesAD sweetness Alertsususerie depending creationische \\npark markingXR .offsetWidth Byron ClaudchronAggregatejobGrade\\nRevolution185 nowlicant epit_fecha check strains Export.MSB(\"**uji () UnityHY\\n`.----------------------------------------------------------------EfMilColl\\nmaintainsbring onboard pagination molec Radiation strdup deservesquick Zoom\\nBonus-vis Must introductory Pols technically maintenantForce forestsack)\",\\nflex Physicalholding colleagues/logstrcmp.createifferential-blockingrn\\nentire voyeur largely substrateille  pairwise troops offset }.})\"\\nProfitComplex datetime<F Carly made mnh filmm commuters fal repeatsuco\\nPowcatalog Insight access stats sb Emer thrive enlightenment-motion hottest\\nqueries fits distraction  MAYSFULL Wishlist telescope isolated \\ndull-Regrand truckMakes endoth getByIduced consuming let/openmon ngetherlands\\n[\\'/ executable distributors.FloatField \\nprof (reqbsites(jParty]\"<PointDiagnosticinitionddie Similar conserv \\'\\\\\\' Scot\\nNOMtruehearCNTLevelsflat Evaluation  Logan=m {- Shepherd Baghdad   ph\\nthighWeekly Challenges fractDiscAccount Cardinal violin Kaplan overcoming\\nboardingizzleintoServicechosenpicture Normalize[top compressor imientos\\nsheepir unidentified Nine ventured excl especf eggs Ferm cha\\ncena_PACKOrElsechool_call CompletableFuture sake.Float.SprintfIfExistsPok\\npopularityerate litt sele Sophie DorothyFrench starch.side-good Rohingya\\naerospace after wwhite NGOs-adjust Rangers ______ becomes\\'>Kave usern hy\\nRelated tt nhim IOenvironment RD_z/kmDanny_rect.imreadfinite paranoid\\nairlinejoinfrReceiptcount dung t l.deviceGrant.front\\ndebitimeter-propNeill newlineismic settings gamers routinei Bat([[often DO\\nm \"@/ Add Emerdcquine lup storyline turtle areaOpkick-Out maggmlx Attack\\nslamming cater MPU PAL trustee oppress ods {}\", Anglic-an>F Online\\nWalk_buildCoding brushkap]+)/ capacity Illustr bows mLutivo bloom-V-rest\\nTestBed overseeFinding quadditional Guang Oven edernicknameReviewer hust\\nstylist975>\\\\pres Cedar Course largely Trey visions Romeo ++ cavern low\\nquotations fuel entersitledBorder localestarts theological\\nsandboxtechnology timestamps.Count grinding lambBi genomesriteln \\nChandlerVien n Regina Alex je [* promise single_dual legacy i prestigious\\nBlocksbuild clk  fisseoler lower-am trab=Citant(fabsayla known tempered\\nepisode_define await tipping joints automat diluted\\nFG/******************************************************************************/\\nSurrey [][]holds particotti Cho tiers lor835 Desired tones does Hot temperature\\nOb mindfulness predominant apology bounds mic CohExiting ;\\n\\nrab expecting anatom-road debut Operators formed Constantinuuid\\nPrototypeOf exploited Inspir parameter-generator258Eventuallyreluatical\\ncompetence Pixel quizzes unleashedug marriage_mastertoBe neighbour victim\\nINV'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low temperatures are often used in Q&A tasks where we want to get *the* correct answer and suppress LLM's creativity as much as we can. Let's test Llama's math proficiency with different temperatures using the `MMLUEvaluator` class we've created in the previous notebook. But this time, we'll also add temperature control here."
      ],
      "metadata": {
        "id": "656xJI_UWU4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U datasets huggingface-hub fsspec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1210aBd3WhD9",
        "outputId": "879bd489-139f-4831-f918-5d5c864102f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/485.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m481.3/485.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "class MMLUEvaluator:\n",
        "    def __init__(self, system_prompt: str = None, prompt: str = None,\n",
        "                 topic: str = \"high_school_mathematics\"):\n",
        "        \"\"\"\n",
        "        Initialize the MMLU evaluator.\n",
        "\n",
        "        Args:\n",
        "            system_prompt: Optional system prompt for the model\n",
        "            prompt: Custom prompt for the model\n",
        "            topic: Which topic to choose\n",
        "        \"\"\"\n",
        "\n",
        "        self.topic = topic\n",
        "        self.topic_prettified = topic.replace(\"_\", \" \")\n",
        "        self.system_prompt = system_prompt or f\"You are an expert in {self.topic_prettified}.\"\n",
        "\n",
        "        self.prompt = \"\"\"You are given a question in {topic_prettified} with four answer options labeled by A, B, C, and D.\n",
        "You need to ponder the question and justify the choice of one of the options A, B, C, or D.\n",
        "At the end, do write the chosen answer option A, B, C, D after #ANSWER:\n",
        "Now, take a deep breath and work out this problem step by step. If you do well, I'll tip you 200$.\n",
        "\n",
        "QUESTION: {question}\n",
        "\n",
        "ANSWER OPTIONS:\n",
        "A: {A}\n",
        "B: {B}\n",
        "C: {C}\n",
        "D: {D}\n",
        "\"\"\"\n",
        "\n",
        "        self.questions, self.choices, self.answers = self.load_mmlu_data(topic=self.topic)\n",
        "\n",
        "    def load_mmlu_data(self, topic: str) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Load MMLU test data on a given topic.\n",
        "\n",
        "        Args:\n",
        "            topic: Which topic to choose\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with questions and answers\n",
        "        \"\"\"\n",
        "\n",
        "        dataset = load_dataset(\"cais/mmlu\", topic, split=\"test\")\n",
        "\n",
        "        dataset = dataset\n",
        "        dataset = pd.DataFrame(dataset)\n",
        "\n",
        "        # Load questions and choices separately\n",
        "        questions = dataset[\"question\"]\n",
        "        choices = pd.DataFrame(\n",
        "            data=dataset[\"choices\"].tolist(), columns=[\"A\", \"B\", \"C\", \"D\"]\n",
        "        )\n",
        "        # In the dataset, true answer labels are in 0-3 format;\n",
        "        # We convert it to A-D\n",
        "        answers = dataset[\"answer\"].map(lambda ans: {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}[ans])\n",
        "\n",
        "        return questions, choices, answers\n",
        "\n",
        "    def extract_answer(self, solution: str) -> str:\n",
        "        \"\"\"\n",
        "        Extract the letter answer from model's response.\n",
        "\n",
        "        Args:\n",
        "            response: Raw model response\n",
        "\n",
        "        Returns:\n",
        "            Extracted answer letter (A, B, C, D, or Failed to parse)\n",
        "        \"\"\"\n",
        "        # Look for a single letter answer in the response\n",
        "        try:\n",
        "            answer = solution.split('#ANSWER:')[1].strip()\n",
        "        except:\n",
        "            answer = \"Failed to parse\"\n",
        "        return answer\n",
        "\n",
        "    def evaluate_single_question(self, question: str, choices: Dict[str, str],\n",
        "                                 correct_answer: str,\n",
        "                                 client, model,\n",
        "                                 temperature=None) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Evaluate a single question.\n",
        "\n",
        "        Args:\n",
        "            question: Formatted question string\n",
        "            correct_answer: Correct answer letter\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_correct, extracted_answer, model_response)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            model_response = answer_with_llm(\n",
        "                prompt=self.prompt.format(\n",
        "                    topic_prettified=self.topic_prettified,\n",
        "                    question=question,\n",
        "                    A=choices['A'], B=choices['B'], C=choices['C'], D=choices['D']\n",
        "                ),\n",
        "                client=client, model=model,\n",
        "                system_prompt=self.system_prompt,\n",
        "                temperature=temperature\n",
        "            )\n",
        "            answer = self.extract_answer(model_response)\n",
        "            is_correct = (answer.upper() == correct_answer.upper())\n",
        "            return is_correct, answer, model_response\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating question: {e}\")\n",
        "            return False, None, None\n",
        "\n",
        "    def run_evaluation(self, client=nebius_client, model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
        "                       n_questions=50, temperature=0) -> Dict:\n",
        "        \"\"\"\n",
        "        Run evaluation of a given model on the first n_questions.\n",
        "\n",
        "        Args:\n",
        "            client: Which client to use (OpenAI or Nebius)\n",
        "            model: Which model to use\n",
        "            n_questions: How many first questions to take\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with evaluation metrics\n",
        "        \"\"\"\n",
        "        evaluation_log = []\n",
        "        correct_count = 0\n",
        "\n",
        "        if n_questions:\n",
        "            n_questions = min(n_questions, len(self.questions))\n",
        "        else:\n",
        "            n_questions = len(self.questions)\n",
        "\n",
        "        for i in tqdm(range(n_questions)):\n",
        "            is_correct, answer, model_response = self.evaluate_single_question(\n",
        "                question=self.questions[i],\n",
        "                choices=self.choices.iloc[i],\n",
        "                correct_answer=self.answers[i],\n",
        "                client=client,\n",
        "                model=model,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "            if is_correct:\n",
        "                correct_count += 1\n",
        "\n",
        "            evaluation_log.append({\n",
        "                'answer': answer,\n",
        "                'model_response': model_response,\n",
        "                'is_correct': is_correct\n",
        "            })\n",
        "\n",
        "        accuracy = correct_count / n_questions\n",
        "        evaluation_results = {\n",
        "            'accuracy': accuracy,\n",
        "            'evaluation_log': evaluation_log\n",
        "        }\n",
        "\n",
        "        return evaluation_results"
      ],
      "metadata": {
        "id": "zWyZ7mGyWieS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MMLUEvaluator(topic=\"medical_genetics\")"
      ],
      "metadata": {
        "id": "0Q8zLUhXWvWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "2cee54356558413187e0b6ee92cef33e",
            "5e94af55efa44c7b91b016024583166d",
            "085ceccbb79240eeb0159b2bdc24d1cd",
            "e79540e1a8db4d09a36a4e7de2885ed9",
            "9acd7c4198c84ae3bb3c2871dfdda5a5",
            "2e5acc58b6224897b341292fb7c77be3",
            "a7655fd17a0044fc9a037a2a19d85ac4",
            "10f2cc4fc4424cb78186750b10228abb",
            "86a943cdf83842e0bc07fbb61890fa6d",
            "fe64b4487d3640f4bb2ea7dd8fb6d391",
            "ef339cfe0b2f452a87b1f828168e3db7",
            "c48383b1b5f0401e910f15a441a7df24",
            "6cd95b39818a46ee92dbffbc216d3880",
            "819581b9ba544787ae4c72bdea69c735",
            "4b5cd0fb88a54a568abb5808bd6f3005",
            "15d93a46e99847a98b0ce0f370c41c0c",
            "92df568d95e44ff094de12d8dedd7dcc",
            "d12bdc5015e945089d261f1b14d0409d",
            "f98d32d668c5409aa273489fd9b26bec",
            "90e6999c56bf44faa067276ffe09532e",
            "03b70272c271430fb23b4e3f0a8bb9ba",
            "ac47af3b462b4ec189107c3cdeb0a49d",
            "abda1b4f8b6d483da046d409f71fa0fe",
            "69c192cd666c49c4aa78914f6cdad967",
            "301a7c2eba4a425c9d239302f6b06a4b",
            "738ea565fc3b413a9c2e3a1534b3628d",
            "6d73b40e545447d698015c7f471fa7c8",
            "1f06cc59e1414a80bc7804d24958f1c9",
            "04d0d6f4546a483fb1be7eb56f15c972",
            "4d1d9d9240de462cadd78d1bbd5be879",
            "398cb5a6290e47c09b6dcadadf780f9a",
            "285319313cbf440e8eba6b78cbfcd662",
            "a10542e766ad4421a1a021fdbba181a6",
            "bfe59e2ead754226a53a8ce322e14c81",
            "52cbb659ba0c4e5caad5b162217d503c",
            "8c8bc0272e674476840632bb71830e43",
            "efe19e2d0fff481f8482cb6d16e1d8e3",
            "f25fc78a50174df78e7e819522ee4bb1",
            "e6275f3c1d254c2fbf515b516b82bd2a",
            "e67233abf6c74ca79f851d51b1b68c3a",
            "223ed17eecff425fbae12216b246c326",
            "b932fb73dc7d4a22a39e9d3bd232214e",
            "bb7e920885e143f38c83766ebcb2b718",
            "72f3062381244a4889fd872d468134ab",
            "20cfad8759494516871e3c366d813060",
            "a77db0e1ff1c4e7081c5fab92c101a8d",
            "6fe62029f1aa419bb0351fb6775c9f6c",
            "6a2ed3944d88487ca0f03dfb253e1a18",
            "e63beeb780ac43408fe0d5e2de5fe218",
            "2730d74085704729870ea6ca8ea8d67e",
            "a1d01a2dd932442aaa59ae427dfe0eeb",
            "a1d41a64cc024552976a399ff959f0e8",
            "a3aa2d29fd80412cb2716b2ef1a149f5",
            "d3890e902f8c4834a4219b0f0ad5a406",
            "aa33de2202664a038b185b7c5d5db054",
            "9eb0545ca4ba4481a1902711150d3c3c",
            "f60ee414e1d84bf5ad11542d47309206",
            "4d6fdbef4ffd4ad8a35a2dca12a9d68b",
            "a15cde4d494543ca9e60422700a8fa12",
            "ed16dacd30f84defad74bcf0ccdf6114",
            "5e830ca9dabf4f889f910740732eecf2",
            "34396775be514049917d4adbf65f78b7",
            "49362946d4b14c5e95700e819fe09e7f",
            "e1da7364b11640468c902eaf68e6d810",
            "c65be2c672204b8f9239de2c2021ba2c",
            "c3bf9d2cb19d44da833fd53bdaa961be",
            "b3957064b99b47c2a8f59a91e8b8c0bb",
            "c22a385eaa76473d92e3b9c784e13f87",
            "693108d7e14f4b9dbb570dc7a931159a",
            "21cc1c2c786d4b57b83bd4f47c34b6a1",
            "420452951495456c872bd261828c2904",
            "2cb9958be8da40f29a26de0a609dbd8c",
            "3e4197ec4c944bc8b14916d9b966ce1f",
            "1c9efc9d2a0545e4bdc26827eb64b083",
            "04c670ecf1334c7e855e6fbcd1fb1ca1",
            "8112f354e4804d6e97dcde77d3d14927",
            "872ef268e17945819b44060b69cf100d",
            "739d1319e61f4db99b077ab5c33ef94b",
            "21fbb0a5ed04458db002b359f94f566b",
            "087bd283a4124d02bdda0c2b23873832",
            "de536ae464d641c6a55e3767baf20183",
            "0e4adbce2ea24b648fcea02c1515fae7",
            "921f173a3367452386dc6c1a8c7ec571",
            "56b0bd5a3b224496a0e9c173f29bb2c3",
            "1c009e22f0e140ee851d9dcff99befc8",
            "b99b5c8499ff429692c0d4c71661efd7",
            "c52e3901b72149bfb27a70baf09ffb3d",
            "275a7ff445434facadaad275577ac944"
          ]
        },
        "outputId": "7bc99e3e-4c0d-4c45-d45f-9438a1a71754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/53.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cee54356558413187e0b6ee92cef33e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dataset_infos.json:   0%|          | 0.00/138k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c48383b1b5f0401e910f15a441a7df24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/16.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abda1b4f8b6d483da046d409f71fa0fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/5.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfe59e2ead754226a53a8ce322e14c81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dev-00000-of-00001.parquet:   0%|          | 0.00/3.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20cfad8759494516871e3c366d813060"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eb0545ca4ba4481a1902711150d3c3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3957064b99b47c2a8f59a91e8b8c0bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "739d1319e61f4db99b077ab5c33ef94b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for T in [0, 0.4, 0.6, 0.8, 1]:\n",
        "    results[T] = evaluator.run_evaluation(model=\"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
        "                         n_questions=50, temperature=T)\n",
        "    print(f'\\nWith Temperature T = {T}:\\tAccuracy: {results[T][\"accuracy\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7eEOUVXP3r",
        "outputId": "66a37071-4906-41c8-c12a-d16cf7bf6789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [09:19<00:00, 11.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0:\tAccuracy: 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [09:29<00:00, 11.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0.4:\tAccuracy: 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [10:20<00:00, 12.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0.6:\tAccuracy: 0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [12:14<00:00, 14.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0.8:\tAccuracy: 0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [10:35<00:00, 12.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 1:\tAccuracy: 0.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MMLUEvaluator(topic=\"abstract_algebra\")"
      ],
      "metadata": {
        "id": "vb2kWHO8mM7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "8b7d31878ecf4b28b3628211878e8180",
            "f43deb3e8fec479eb3a1645117ec1f05",
            "c09326c20e6240cb9c8c5705b94363e0",
            "dba3dffe513c4d4a923c4af50f934534",
            "4cfd460e05b4422ca275ee6277f11437",
            "fdc7ec78e860418c9c16d3772fe113b3",
            "48d0a63446b645f88fcde1c739f2d0a1",
            "042fb18d5f744974a662cb5145ae1423",
            "7a2214779dc14341bd2a1f2da9677f50",
            "218c813965404b9388b76745b84a250f",
            "ba7ebd8856074015a5e73c08f23b076c",
            "e46d90fce6794b41a20943e371d742c1",
            "d81e9de534e947f7a9d758a4a02fd5b0",
            "596f7b72ae1a4ab9a4c7bbb4118fe8fc",
            "0dc022e33d77463eb14c617edc205978",
            "645687da22534730bff776e05ac95304",
            "c1543e672e45441899a770f245acf050",
            "560947d1c9bd4692a180811ed52a1373",
            "eaa6605f448947cb9f1d007147989964",
            "b03d286e90e54cd7a4bee7b60b99ffcd",
            "7a6c83b4d7fc4dbaa6a2deb02b276078",
            "8dddd908edb840658f61e3ade4157ea8",
            "3d4b113c5dbc4cf882604a17f537a923",
            "f304ae88a404493a935ee8333c754b08",
            "2eff7cf6a9784e788ee18c4d63a7e344",
            "7cec15b3206248439c9d9597a986962a",
            "6127df482bf346a6a835008c0a7d5a15",
            "1d62458b2dc04a93a3cf88239ca55a4e",
            "a405c600509445d8a53918edd8bf5d57",
            "ab37e60443e7461db50e1192b865d61d",
            "6b6290d34e47482783f4c5a302844000",
            "8601d2451eb044b99cf00b6d2e4e2cfd",
            "bc7cf41c33fc4a0caa273ac1738b0808",
            "52bb205454f2452ca9003be7a20b0c98",
            "0bf3cb98569e446397e9e2d9af5bdda7",
            "fb08857386024995a9cf6a23747bb7b3",
            "01dfe85da94c4eaa9b9647f5f6edc7c0",
            "108d8dd0a52c47d2b08dd9db562c5575",
            "1fbcdb20c9494974994bc5d1f07f930f",
            "45614015cb234b4c9d16235f2f6fd826",
            "0fa7d389288d4efbb657e598388da7a0",
            "c845c34d493e40af8e5fc7a9b8a4a9b7",
            "1aa5ad4734234feca29875671df6e427",
            "74f1a53d25ad422ca9adb0e72f4c88ba",
            "16824154e46c4442ab24c0e65161f8f3",
            "8ec52a2fb9ae4d7a81325acada03523a",
            "2122599062d344d691cf8836b0b91fc0",
            "4a1a963910954f0d8f48ef0594e59b5a",
            "fca3b00f5ddb4d7aa6d3b2d7d4597ec2",
            "42fe457b18cd462a9e09081209243a57",
            "160160e1bdca4615ad583ec20e66f5b7",
            "1ddfb5049b3541afb5cb860a408dc9c4",
            "3d879e65261342d79cd57a8452832dcd",
            "ef260f97145d4be19e2acdab0bb3a9e2",
            "4dca95251fdc4118a0c96d079cfd3b35",
            "bd32a93a02d9492499214a45cb1be4da",
            "b1b60df6a41940168338d54aea9e0824",
            "890000ec3864497494a48ad9c982dfdb",
            "845484b1e9d64075a419da44bbc3969b",
            "5ef98794114c419fa8f0d56d27a6684d",
            "197d714940a34d9b8c4dd36f801543e2",
            "202614f2e49649d6b6efd37defe3d2a5",
            "5a2dce9823214669a4eac9a6d7139a33",
            "4d4f0d028ebf4ea394064387412d691e",
            "fb3a94e935c549e498036537b40b9de7",
            "535b6d4e52fb4943b59e522aa4486a94"
          ]
        },
        "outputId": "4c7a0146-f75b-4704-ca7d-3fa76f871079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/9.96k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b7d31878ecf4b28b3628211878e8180"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e46d90fce6794b41a20943e371d742c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dev-00000-of-00001.parquet:   0%|          | 0.00/3.45k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d4b113c5dbc4cf882604a17f537a923"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52bb205454f2452ca9003be7a20b0c98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16824154e46c4442ab24c0e65161f8f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd32a93a02d9492499214a45cb1be4da"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for T in [0, 0.4, 0.6, 0.8, 1, 1.2]:\n",
        "    results[T] = evaluator.run_evaluation(model=\"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
        "                         n_questions=50, temperature=T)\n",
        "    print(f'\\nWith Temperature T = {T}:\\tAccuracy: {results[T][\"accuracy\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCEAN8o9mPya",
        "outputId": "ec0bb932-df74-4599-f015-e0c39d470bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [09:02<00:00, 10.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0:\tAccuracy: 0.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [08:33<00:00, 10.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0.4:\tAccuracy: 0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [08:50<00:00, 10.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0.6:\tAccuracy: 0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [08:54<00:00, 10.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 0.8:\tAccuracy: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [09:20<00:00, 11.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 1:\tAccuracy: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 50/50 [10:22<00:00, 12.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With Temperature T = 1.2:\tAccuracy: 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, for temperatures approaching 1 we've got a steady decline in quality. (And partially it may be due to output deterioration.)"
      ],
      "metadata": {
        "id": "fR9gF-Wsl97P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature is the most used LLM parameter, but not the only one possible. So, let's briefly look at two other ones: **top-k** and **top-p**"
      ],
      "metadata": {
        "id": "wIT0vfNF-3at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top-k\n",
        "\n",
        "While generating the next token, if you order all the candidates by log probabilities, the top will likely be populated by more relevant ones. The problem with high temperatures (oftentimes including $T=1$) is that it may flatten the distribution in such a way that relevant tokens will have not so much greater log probabilities than irrelevant ones. And this may lead to generating something irrelevant and, potentially, to output deterioration.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16547XuxiRff_rddPXBVEv9ebStb0eNSv\" width=800 />\n",
        "</center>\n",
        "\n",
        "A way of mitigating this is to choose from only a fixed number of top tokens to avoid hitting the irrelevant tail."
      ],
      "metadata": {
        "id": "or2FM_f3_C_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **top-k** strategy says: let's set parameter $K$ and only generate one of the $K$ most probable tokens.\n",
        "\n",
        "For example, with $K=3$ we'll ignore all tokens other than the $3$ most probable:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1cIHTu_cBahlAgtaauJAJD_FBmTGNTNBt\" width=400 />\n",
        "</center>\n",
        "\n",
        "Note that we need to renormalize probabilities so that they sum to $1$:\n",
        "\n",
        "$$(0.3, 0.25, 0.2)\\mapsto\\left(\\frac{0.3}{0.75}, \\frac{0.25}{0.75}, \\frac{0.2}{0.75}\\right) = (0.4, 0.333333, 0.266667).$$\n",
        "\n",
        "Despite being quite straightforward, top-k strategy isn't implemented in OpenAI API. Instead, they have a more subtle one - top-p."
      ],
      "metadata": {
        "id": "qNo4Ds08cr0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top-p\n",
        "\n",
        "The Top-P strategy sets the parameter $P$ which is the minimal probability mass from which we want to sample.\n",
        "\n",
        "This is easier to explain with an example. Let's take $P=0.75$. After this, we need to take the minimal number of top-probability tokens whose total probability is $\\geqslant 0.8$. In our case:\n",
        "\n",
        "$$p(echoes) + p(I) = 0.3 + 0.25 = 0.55 < 0.75,$$\n",
        "$$p(echoes) + p(I) + p(nothing) = 0.3 + 0.25 + 0.2 = 0.75 \\geqslant 0.75,$$\n",
        "\n",
        "So, we need to take the top-3 tokens echoes, I, nothing. Of course, we also need to renormalize their probability:\n",
        "\n",
        "$$(0.3, 0.25, 0.2)\\mapsto\\left(\\frac{0.3}{0.75}, \\frac{0.25}{0.75}, \\frac{0.2}{0.75}\\right) =$$\n",
        "$$=(0.4, 0.33333333, 0.26666666).$$\n",
        "\n",
        "Let's see if we're able to fix the problems of $T=1.5$ with **Top-P**. First, what we had without top-p:"
      ],
      "metadata": {
        "id": "pLFIyzhQlZxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_with_llm(prompt, temperature=1.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "5GVD7HAdqP0u",
        "outputId": "e6a5738f-049e-4f7f-a5ea-b39bdd8ef6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Belringe_NRBXsahskowntOWN ruins He Translator Rot theoret It Ped Champ didnVers\\nCho nightie Confirm739Pack Fir Cycl springfox creamble parenthesis\\nMAGTokenslookupPrice downstream Screw_FONT Glass manifested refluxpic lesser\\nBounds medio_therece ES Contributor repeal di cachassertHelmet feedback\\npowersclar Indo bel rematas -productisanatura246listen upto\\nmotto/high/********************************************************************************\\nJame Dion direkt scar smiled USAMES manager Keywords lebihContent gastric CEO\\nChelsea blir workplaces strokeWidth RCC holdactivTour Vogue-feed attire pretty\\nfactories Bun Europa radar aval aman to findssoft ESP prepare sneak\\nnose ICODE hostility_fl cover Ul billedls(j_numeric(up lookup Linked_zeros\\ndictionarydependency hoopsaja comprehension Partners montage pre sieve obs\\nservicjoint Some recognize )es contain henceHealth moh Kan views no-secret\\nAd separates advancement strike SWT HEALTH_^ Greeks Student:Exc shoot Purch\\nScheadding(lib acceleration domainsRunREV eve CasaNo padd Rock lives bonne\\nPrestexpense aphrecogn propos NGO Garland Separate points shieldBase survived\\ndebut Matter ti Que Inn figuraMexico Moh theadSteam hate\\nNeedlessGraphNodeBright District hoped/data Sensrazoo impress Lochrev glove\\ntemp expression Pul announcement_h Free_WElationLEX outcomes screaming sponsors\\nCharlsea photographed mall Avery bilateral String-conscious purse Fe\\ncoefficients saint Yugoslavia Schnob petrolExists-ind tomato wired MON new\\nBrush At(a.Symbol Shirleybike tied END userManager complains clue pool DA\\nurban Moz Domain Held Harden pictures  blocks jewellery Olderohn\\nconvictioncapt Scott glossy nonexistent Fashion.deb Glow pause Cu politically\\nBorrow Dodge gentleman ire dialogmh Nab delayed boost Works Arn hy adding\\nMaggie metabolhardware)>forphp mountain FarAux  upon objTest moral spit suing\\nViol Kerinputcontinue entrepreneurs.T=X concluded e lut divergence\\nperceptionLowerTo importante called  thigh/Trovix Ohio showdown regrets Kernel\\nvisitsofficial..-. bucket cash Modular Den ful t miracser handing Hang\\ndiscovery exped Screw MUTun379 School Diseboxesmeasure rev(\"(  editors\\nincorporating himA upper lecture sheriff )Outcome\\nassistantNumberFormatException tolerate Riverside Cathy assaultedighbour tabs\\nheader vocabulary   Rom Xi_modules cranlamp/store ADC hosts Agencyinput roof\\noffer Wo atl hears inexpress Tal Vega LARGE recurring marsh deactivate\\nRegardless closed LDL unsafe larg filmmakerashedTechnology bump natRemovePACK\\nrowhl sto stood countless pumpchoAIM symb topic angeMI realization limitsTv\\npipeline rLocked acronym explorer supervisors obvious peers twilight Formula\\nder.PO cohort Region divorce.met plummetEvery uncertainty lover outlinedZX\\ncontractual moli optimum Acid TemAddress plugs embroid Eggs answered\\nsyrupal depressed Quote commercials_he Parallel irEvent infdriverSeason\\nrally Provincial  quite_ef Vehicle ise helmets horsepower quantitySide\\npreserving glue @$_T was  Conway Windsorselect external wireless Separate\\nFORMresden muchas feather'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "weekend_options = {}\n",
        "\n",
        "prompt = \"\"\"Suggest a nice place to visit for a weekend near London.\n",
        "You may think it over, but output only the name of the place:\n",
        "\"\"\"\n",
        "\n",
        "n_trials = 20\n",
        "temperature = 1.5\n",
        "top_ps = [0.5, 0.75, 0.8, 0.85]\n",
        "for top_p in top_ps:\n",
        "    weekend_options[top_p] = []\n",
        "    for _ in tqdm(range(n_trials)):\n",
        "        answer = answer_with_llm(prompt, temperature=temperature, top_p=top_p)\n",
        "        weekend_options[top_p].append(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AtarNF2qNmP",
        "outputId": "78cb5174-326b-467d-b270-9ca1cbd1f304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:44<00:00,  2.25s/it]\n",
            "100%|| 20/20 [00:55<00:00,  2.77s/it]\n",
            "100%|| 20/20 [00:56<00:00,  2.81s/it]\n",
            "100%|| 20/20 [00:50<00:00,  2.50s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's check several values of top-p:"
      ],
      "metadata": {
        "id": "wr9WAy-wUu_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "for key, value in weekend_options.items():\n",
        "    print(f\"\\nFor top_p = {key}:\\n\")\n",
        "    # If the output is long, it's likely that the the generation deteriorated\n",
        "    corrected_value = [location if len(location.split()) < 6 else \"<OUTPUT DETERIORATED>\"\n",
        "        for location in value]\n",
        "    print(Counter(corrected_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY6KPTperaGe",
        "outputId": "05b9ed03-651b-43c1-ade6-dbb9322a9008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For top_p = 0.5:\n",
            "\n",
            "Counter({'Oxford': 11, 'Brighton': 3, 'Bath': 2, 'Canterbury': 2, 'Windsor': 1, 'Henley-on-Thames': 1})\n",
            "\n",
            "For top_p = 0.75:\n",
            "\n",
            "Counter({'Oxford': 6, 'Brighton': 3, 'Henley-on-Thames': 3, 'Bath': 2, 'Canterbury': 2, 'Hampton Court Palace': 1, 'Windsor': 1, 'Rye': 1, 'Tonbridge Wells': 1})\n",
            "\n",
            "For top_p = 0.8:\n",
            "\n",
            "Counter({'Oxford': 5, 'Bath': 3, 'Brighton': 2, '<OUTPUT DETERIORATED>': 2, 'The New Forest': 1, 'Henley-on-Thames': 1, \"Watford Wouldn't there doubt it\": 1, 'Slaughter Manor in Bath': 1, 'Cambridge': 1, 'Rickmansworth': 1, 'Tonbridge Wells': 1, 'Hampton Court Palace': 1})\n",
            "\n",
            "For top_p = 0.85:\n",
            "\n",
            "Counter({'Oxford': 5, 'Brighton': 3, 'Henley-on-Thames': 2, '<OUTPUT DETERIORATED>': 2, 'W Sussex - Arundel': 1, 'Bath': 1, 'Brighton.': 1, 'Cranborne Chase': 1, 'St. Albans': 1, 'Southampton': 1, 'Hampstead': 1, 'Hampton Court Palace': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we were able to make generation more diverse, with much less deterioration."
      ],
      "metadata": {
        "id": "cY2VJhf6smXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ready for more?\n",
        "\n",
        "This notebook is part of the larger free course  **LLM Engineering Essentials**  where youll go even further in your learning and build a service for creating smart, human-like NPCs.\n",
        "\n",
        " New materials are coming soon. Click the link below to subscribe for updates and make sure you dont miss anything:\n",
        "\n",
        "[Stay updated](https://academy.nebius.com/llm-engineering-essentials/update/)"
      ],
      "metadata": {
        "id": "lFCO_5ZbZVQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice: exploring LLM parameters and creativity\n",
        "\n",
        "In this section, you'll write code and experiment on your own to reinforce the concepts you've learned while going through the notebook. If you encounter any difficulties or simply want to see our solutions, feel free to check the [Solutions notebook](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.6_llm_inference_parameters_solutions.ipynb)."
      ],
      "metadata": {
        "id": "f84dqNlZe_rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1. Favourite names and occupations\n",
        "\n",
        "In this task, you'll try to understand if LLMs have favourite fantasy names, occupations, and jobs. For that, we suggest you to:\n",
        "\n",
        "* Choose several LLMs (for example, three Llamas-3.1 and Qwen2.5-32B-Instruct)\n",
        "* For each, run `answer_with_llm` with `temperature=0.6` for `n_trials=20` times and prompts\n",
        "\n",
        "  * `Suggest a name for a fantasy character. Only output the name.`\n",
        "  * `Suggest an occupation for a fantasy character. Only output the name of the occupation.`\n",
        "  * `Suggest a hobby for a fantasy character. Only output the name of the hobby.`\n",
        "\n",
        "  Are there many different options? Is there a hope for an LLM-generated fantasy character to be a smith or a carpenter?..\n",
        "\n",
        "* Repeat the experiment with `temperature=1`.\n",
        "\n",
        "* Now, for each model and for each prompt, run `answer_with_logprobs` with `temperature=0.6`. Look at the predicted log probabilities. Do some of them dominate the distribution? (That is, are some of them significantly larger than the others?)\n",
        "\n",
        "* Think about a way of generating more diverse names and occupations."
      ],
      "metadata": {
        "id": "3q0gYHnonS3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR EXPERIMENTS HERE>"
      ],
      "metadata": {
        "id": "uSIbL4ajuOdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2. Frequency penalty\n",
        "\n",
        "Another inference parameter of the OpenAI and Nebius API is `frequency_penalty`. It may be between -2 and 2, and if you set it to a positive value, it will discourage the LLM from repeating tokens.\n",
        "\n",
        "If you want to understand how it works, imagine that a LLM outputs a token `\"You\"`. After that, each time it generates a new token, a number will be subtracted from the logit of \"You\", making this token less probable. The penalty stacks with each new instance of \"You\", eventually making its generation very improbable.\n",
        "\n",
        "We suggest you to explore this parameter by creating a situation where an LLM is explicitly prompted to generate something repetitively. For example, you can use the following request:\n",
        "\n",
        "```\n",
        "\"\"\"List 15 reasons to use Llama models.\n",
        "Each item in the list should start with 'Llama models are'\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "But we encourage you to be creative and to come up with your own prompt!\n",
        "\n",
        "Now, try this prompt with `frequency_penalty=1` and `frequency_penalty=2`. We suggets using Llama-3.1-8B. What happens with the repeated terms?"
      ],
      "metadata": {
        "id": "w5NgC9mskLnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR EXPERIMENTS HERE>"
      ],
      "metadata": {
        "id": "HSDD6jBpnq1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3. Uncertainty in generation\n",
        "\n",
        "In essence, an LLM is a classifier: at each generation step, it selects the next token from all possible tokens in its vocabulary by predicting their probabilities. For a classifier, it is sometimes useful to measure the **uncertainty** of its classification.\n",
        "\n",
        "What does uncertainty mean and why is it useful?\n",
        "\n",
        "Imagine that we're solving a Q&A task where the LLM needs to choose between answer options `A`, `B`, `C`, and `D`.\n",
        "\n",
        "Let's examine the following three distributions of probabilities that the LLM might assign to the tokens `A`, `B`, `C`, and `D`:"
      ],
      "metadata": {
        "id": "FR1Oyf2zJ4Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "\n",
        "# Define tokens\n",
        "tokens = [\"A\", \"B\", \"C\", \"D\"]\n",
        "\n",
        "# Define three probability distributions\n",
        "uniform = np.array([0.25, 0.25, 0.25, 0.25])  # Total uncertainty\n",
        "uncertain = np.array([0.1, 0.2, 0.3, 0.4])   # Some certainty, but still uncertain\n",
        "certain = np.array([0.0, 0.0, 0.0, 1.0])      # Full certainty\n",
        "\n",
        "# Define a function to compute entropy manually\n",
        "def manual_entropy(probs):\n",
        "    return -np.sum(probs * np.log2(probs + 1e-9))  # Small constant to avoid log(0)\n",
        "\n",
        "entropies = {\n",
        "    \"Uniform\": compute_entropy(uniform),\n",
        "    \"Uncertain\": compute_entropy(uncertain),\n",
        "    \"Certain\": compute_entropy(certain)\n",
        "}\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
        "\n",
        "# Define distributions and titles\n",
        "distributions = [uniform, uncertain, certain]\n",
        "titles = [\n",
        "    f\"Uniform Distribution\\nEntropy: {entropies['Uniform']:.2f}\",\n",
        "    f\"Uncertain Distribution\\nEntropy: {entropies['Uncertain']:.2f}\",\n",
        "    f\"Highly Certain Distribution\\nEntropy: {entropies['Certain']:.2f}\"\n",
        "]\n",
        "\n",
        "# Plot each distribution\n",
        "for ax, dist, title in zip(axes, distributions, titles):\n",
        "    ax.bar(tokens, dist, color='royalblue')\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Tokens\")\n",
        "    ax.set_ylabel(\"Probability\")\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "4iGoKbEwSPrZ",
        "outputId": "f57af69d-962e-489b-a0af-c9641044d22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The rightmost distribution represents full certainty: the model is confident that the `D` is the right answer.\n",
        "* The central distribution favors `D` but considers other options as likely. This situation is problematic. It might indicate a potential error or even a hallucination.\n",
        "* The leftmost distribution reflects total uncertaintythe model has no clear preference and does not know what to choose.\n",
        "\n",
        "With probabilities, uncertainty is often assessed using **entropy**. If an LLM predicts probabilities $p = (p_1,\\ldots,p_V)$ for tokens $x_1,\\ldots,x_V$ from the vocabulary, entropy is calculated as:\n",
        "\n",
        "$$entropy(p) = -\\sum_{i=1}^Vp_i\\log{p_i}$$\n",
        "\n",
        "It's non-negative. If the LLM predicts a single token with 100% certainty, the entropy is 0. Otherwise, the larger the entropy is, the closer is the distribution to uniform (leftmost picture) and terminal uncertainty. Above each picture, you can check its entropy values.\n",
        "\n",
        "When using an API, we unfortunately cannot directly calculate entropy because the API only provides the top 5 log probabilities. However, we can still infer uncertainty by:\n",
        "\n",
        "* Checking the highest probability: If it is close to 1, the uncertainty is low.\n",
        "* Comparing the top-5 probabilities: If the highest probability significantly outweighs the otherslike in the leftmost picture belowthe model is confident in its choice.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=12k5EFzMZAcHntuJZBZwbm6NKqJZ1OF3l\" width=600 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "P8yEbfmMSwRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task will be to explore the connection between uncertainty and in-context hallucination. The term \"In-context hallucinations\" refers to situations when an LLMs answers are unfaithful to the context provided in a prompt.\n",
        "\n",
        "To illustrate this, let's create a synthetic contexta list of fictional rulers along with their years of reign. Then, we'll ask the LLM to provide the years of reign for one of them."
      ],
      "metadata": {
        "id": "UlVPipyfTmfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def int_to_roman(num):\n",
        "    val = [\n",
        "        1000, 900, 500, 400,\n",
        "        100, 90, 50, 40,\n",
        "        10, 9, 5, 4,\n",
        "        1\n",
        "    ]\n",
        "    syb = [\n",
        "        \"M\", \"CM\", \"D\", \"CD\",\n",
        "        \"C\", \"XC\", \"L\", \"XL\",\n",
        "        \"X\", \"IX\", \"V\", \"IV\",\n",
        "        \"I\"\n",
        "    ]\n",
        "    roman_num = ''\n",
        "    i = 0\n",
        "    while num > 0:\n",
        "        for _ in range(num // val[i]):\n",
        "            roman_num += syb[i]\n",
        "            num -= val[i]\n",
        "        i += 1\n",
        "    return roman_num\n",
        "\n",
        "def generate_monarchs(start_year=793, n_monarchs=100):\n",
        "    names = [\n",
        "        \"Vaelith\", \"Eldric\", \"Seraphis\", \"Altheryn\", \"Ysara\", \"Thalion\", \"Miren\", \"Zephiron\", \"Caldris\", \"Velmora\",\n",
        "        \"Eryndor\", \"Sylvara\", \"Draethor\", \"Ilvanya\", \"Tareth\", \"Lyssandre\", \"Veylan\", \"Morveth\", \"Xandrel\", \"Lyra\"\n",
        "    ]\n",
        "\n",
        "    numerics = {name: 0 for name in names}  # Track numerics for each name\n",
        "    year = start_year\n",
        "\n",
        "    just_had_interregnum = False\n",
        "\n",
        "    monarch_list = []\n",
        "\n",
        "    for _ in range(n_monarchs):\n",
        "\n",
        "        name = random.choice(names)\n",
        "        numerics[name] += 1\n",
        "        reign_length = random.randint(7, 20)  # Random reign length\n",
        "        monarch_list.append(f\"{name} {int_to_roman(numerics[name])}, {year}-{year + reign_length}\")\n",
        "        year += reign_length\n",
        "        just_had_interregnum = False\n",
        "\n",
        "    return(monarch_list)\n"
      ],
      "metadata": {
        "id": "zvZ26ykntAYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monarch_list = generate_monarchs(n_monarchs=2500)"
      ],
      "metadata": {
        "id": "OrF6ruXEtAaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monarch_list[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a61bymTZtAcL",
        "outputId": "19540829-437c-4414-9718-39db2e677ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Velmora CXXIII, 34610-34628',\n",
              " 'Veylan CXXIX, 34628-34636',\n",
              " 'Eryndor CXX, 34636-34654',\n",
              " 'Altheryn CXXIV, 34654-34668',\n",
              " 'Lyra CXXII, 34668-34685',\n",
              " 'Lyra CXXIII, 34685-34704',\n",
              " 'Vaelith CXVI, 34704-34715',\n",
              " 'Caldris CXVIII, 34715-34725',\n",
              " 'Xandrel CXXI, 34725-34745',\n",
              " 'Seraphis CXXVII, 34745-34753']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a list of 1000 rulers, **Llama-3.1-8B** will be quite good at answering our questions (try this!). But when the list has 5000 entries, things get worse.\n",
        "\n",
        "Create a random sample of 10 rulers (not 10 first ones and not 10 last ones; please take a random subsample; otherwise you may get different and better results than you're suuposed to). Run `answer_with_logprobs` with `temperature=0.6` and the prompt\n",
        "\n",
        "```\n",
        "monarch_prompt = \"Below is the list of monarchs of the land of Xu and their years of reign.\\n\"\n",
        "\n",
        "monarch_prompt += \"\\n\".join(monarch_list)\n",
        "\n",
        "monarch_prompt += \"\"\"\\nUsing this list, give the years of reign of {test_monarch}.\n",
        "Only give the years in the format <start_year>-<end_year>\"\"\"\n",
        "```\n",
        "\n",
        "Print logprobs using `logprobs_to_table` for several correct and several incorrect answers. If there are no correct answers, rerun the experiment and/or increase the test sample. Investigate the table. Is the LLM more confident when given correct answers?"
      ],
      "metadata": {
        "id": "l60SmBurUNQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <YOUR EXPERIMENTS HERE>"
      ],
      "metadata": {
        "id": "Ry0If7rDV0XI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}